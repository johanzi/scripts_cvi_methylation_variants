---
title: "High impact mutations drive DNA methylation variation after colonization of a novel habitat"
author: "Johan Zicola"
date: "`r format(Sys.time())`"
output:
  html_notebook:
    toc: true
  pdf_document:
    toc: true
  github_document:
    toc: true
  html_document:
    toc: true
    df_print: paged
documentclass: article
classoption: a4paper
geometry: margin=1in
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = FALSE)
```

```{r,echo=FALSE,message=FALSE,warning=FALSE}
# Set so that long lines in R will be wrapped:
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 80), tidy = TRUE)
```


# Overview

This documentation explains step by step how was performed the analysis on whole-genome bisulfite sequencing (WGBS) data on African *Arabidopsis thaliana* accessions (Morocco and Cape Verde) and the reanalysis of a subset of the WGBS data from the 1001 Genome Project (1001GP) ([Kawakatsu et al., 2016](http://www.sciencedirect.com/science/article/pii/S0092867416308522)) and the RNA-seq performed on Cape Verde accessions.


# WGBS library preparation

Libraries were prepared as described previously in [Urich et al. 2012](http://www.nature.com/nprot/journal/v10/n3/full/nprot.2014.114.html) with minor modifications.

# Sequencing

Libraries were pooled based on the 24 NEXTFlex Bisulfite-Seq barcodes (BiooScientific) for multiplex sequencing on the HiSeq3000 sequencer (Illumina) in 150 bp single-end mode.  1 Gb (7 M reads) of data were ordered for each library (minimum required by the sequencing facility). Reads were trimmed from adapters by the sequencing facility using Cutadapt ([Martin et al., 2011](http://journal.embnet.org/index.php/embnetjournal/article/view/200)). Visual inspection on graphics produced by [fastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) was used to visually determine the quality of the reads.

# Softwares required

* Bismark (v0.19.0)
* Python3.5
* GEMMA (v0.94)
* vcftools (v0.1.14)
* bcftools (v1.2)
* bwa (v0.7.15)
* R (>3.3.0) with the libraries indicated in the scripts
* [SRA tool kit](https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=toolkit_doc) from NCBI
* FastQC v0.11.9
* multiqc v1.6
* cutadapt v2.9
* methylKit (v1.14.2) R package and dependencies

# Reanalysis of the 1001 GP data


## Get information samples

Working directory: `/srv/netscratch/dep_coupland/grp_hancock/johan/bs-seq_data_1001`

Go to NCBI SRA selector for project PRJNA187927 (SALK La Jolla) and PRJNA236110 (GMI Vienna)
Web: https://www.ncbi.nlm.nih.gov/Traces/study/?go=home enter PRJNA187927, Download the SraRunTable.txt (478 samples)

`mv SraRunTable.txt SraRunTable_SALK.txt`

Web: https://www.ncbi.nlm.nih.gov/Traces/study/?go=home enter PRJNA236110, Download the SraRunTable.txt (2215 samples)

`mv SraRunTable.txt SraRunTable_GMI.txt`

Go to http://1001genomes.org/accessions.html and download the csv file (link at the bottom of the page)

Convert CSV to tab-separated file

```{bash}
sed 's/,/\t/g' query.txt > accessions_1001genome.txt
```

A subset of 526 accessions were selected, discarding accessions from USA and replicates. A dataframe containing details about each accessions was created and put in `accessions_1001GP_figure1.txt`.

## Download data

Select SRR names of each the 526 accessions to download

```{bash}
cut -f2 accessions_1001GP_figure1.txt > to_download.txt
```

The script `download_sra.sh` retrieves fastq file for each SRR number.

```{bash}
i=$1

if [[ ! -e ${i}.sra ]]; then
  first_6_chars=$(echo $i | cut -c1-6)
  accession="${i%.*}"
  
  # Download SRA file
  echo "wget ftp://ftp-trace.ncbi.nih.gov/sra/sra-instant/reads/ByRun/sra/SRR/${first_6_chars}/${accession}/${accession}.sra"
  wget ftp://ftp-trace.ncbi.nih.gov/sra/sra-instant/reads/ByRun/sra/SRR/${first_6_chars}/${accession}/${accession}.sra
  
  # Extract fastq file from SRA
  echo "fastq-dump --split-3 ${i}.sra"
  fastq-dump --split-3 ${i}.sra
  
  # Compress fastq file(s) (1 or 2 files for SE or PE libraries, respectively)
  gzip ${i}*.fastq
  
  # Remove SRA file
  rm ${i}.sra
else
  echo "${i}.sra already exists"
fi

```

Download the data

```{bash}

# Launch script in bsub
while read i; do
  bash download_sra.sh $i
done < to_download.txt

```


## Mapping with Bismark

Reads were mapped on *A. thaliana* TAIR10 reference [fasta file](https://www.arabidopsis.org/download_files/Genes/TAIR10_genome_release/TAIR10_chromosome_files/TAIR10_chr_all.fas). Note that the fasta file contains the 5 chromosomes and the 2 plastids (chloroplast and mitochondria). In order to be processed by the R package methylKit ([Akalin et al., 2011](https://doi.org/10.1186/gb-2012-13-10-r87)), the cytosine report files from Bismark were generated for each chromosome and each methylation context. In order to perform the analysis on many accessions, the bash script [run_bismark.sh](scripts/run_bismark.sh) performs Bismark analysis step-by-step.

Note that absolute paths can be given, the output files will be generated in the specified output directory (argument `-o`) or by default in the directory containing the input fastq file if no -o argument is specified. While running, the script will echo each step performed, which can be redirected to a log file.

The script will take care of:
* Building the bismark reference genome
* Perform the alignment
* Remove duplicate reads from the bam file 
* Extract the methylation status and generate coverage and bedGraph files (visualization in SeqMonk and IGV)
* Generate cytosine reports (used as input file for methylKit R package)
* Calculate conversion efficiency (based on spurious non-converted cytosines from the chloroplast genome) 

To get more information on how run_bismark.sh is working:

```{bash}
bash run_bismark.sh -h
```
The code itself contains comments for each step so have look at it and tweak it to your needs.


### Get reference genome

Download the fasta file for *A. thaliana* TAIR10 reference:

```{bash}
# Download fasta file
wget https://www.arabidopsis.org/download_files/Genes/TAIR10_genome_release/TAIR10_chromosome_files/TAIR10_chr_all.fas

# Rename chromosomes to add prefix "Chr" (easier to retrieve information, e.g. Chr1 rather than 1)
sed -i 's/^>\([1-5]\)/>Chr\1/g' TAIR10_chr_all.fas 

# Move the file in "/path/to/dir_fasta/"
mv TAIR10_chr_all.fas /path/to/dir_fasta/

```



### Mapping single-end data

The data from the 1001 GP have a mix of SE and PE data, put fastq files in separate folders.

```{bash}
# Split SE and PE data in different folders
mkdir PE_data
mkdir SE_data

# Move paired-end data in PE_data
mv *_1.fastq.gz PE_data/
mv *_2.fastq.gz PE_data/

# Move the rest (SE data) into SE_data
mv *fastq.gz SE_data

```

Map the reads with the light mode on (remove unnecessary intermediary files) with the flag `-l`

```{bash}
while read i; do
bash run_all_bismark.sh -l -r </path/to/dir_fasta/> -1 ${i} -o </path/to/output/> 
done < <(ls *fastq.gz)

```

#### Assess mapping efficiency

```{bash}

for i in *bismark_bt2_SE_report.txt; do
  library=$(echo $i | cut -d'_' -f1,2)
  map=$(grep "Mapping efficiency" $i | cut -d':' -f2 -)
  echo -e "${library}\t${map}" >> mapping_efficiency.txt
done
```

Put data in excel and calculate average and SD
average: 64.89%
Stdev: 9.34%

#### Assess conversion efficiency

```{bash}
for i in *_report.conversion_efficiency.txt; do 
  name=$(echo $i | cut -d'_' -f1,2) 
  line=$(tail -n1 $i | cut -f3)
  echo $name $line
done >> conversion_efficiency.txt
```

Put data in excel and calculate average and SD

average: 99.52%
Stdev: 0.38%


### Mapping paired-end data

```{bash}

# Get single name for each pair data
ls *fastq.gz | cut -d'_' -f1,2 | uniq > list_fastq_files.txt

while read i; do
          fastq1=${i}_1.fastq.gz
          fastq2=${i}_2.fastq.gz
	        bash run_all_bismark.sh -l -r </path/to/dir_fasta/> -1 $fastq1 -2 $fastq2 -o </path/to/output/> 
done < list_fastq_files.txt

```

#### Assess mapping efficiency

```{bash}

cd /srv/netscratch/dep_coupland/grp_hancock/johan/bs-seq_data_1001/fastq_files/1001/PE_data

for i in *bismark_bt2_PE_report.txt.gz; do
  library=$(echo $i | cut -d'_' -f1,2)
  map=$(zgrep "Mapping efficiency" $i | cut -d':' -f2 -)
  echo -e "${library}\t${map}" >> mapping_efficiency.txt
done
```

average: 51.82%
Stdev: 8.21%

Interestingly, the SE end data map at higher efficiency than PE data (about 10% more uniquely mapped reads) and I observed the same trend for the data of project GC_4050. This is probably due to the fact that more reads are unlinked in SE mode and therefore reads mapping in repetitive regions in PE mode are 2 times more numerous as they belong to the same DNA fragment.

#### Assess conversion efficiency

```{bash}
for i in *_report.conversion_efficiency.txt; do 
  name=$(echo $i | cut -d'_' -f1,2) 
  line=$(tail -n1 $i | cut -f3)
  echo $name $line
done >> conversion_efficiency.txt
```

# Analysis of the accessions from Cape Verde and Morocco

We generated WGBS data for 83 accessions from Cape Verde - Santo Antao, 20 from Morocco and diverse mutants (for FBX5 and CMT2). We also included as control the accessions Col-0, Col-3, Doer-10, and UKID116. The data for the fastq files for these samples can be downloaded in the NCBI depository PRJNA612437.

## Download fastq files

1. Go on website https://www.ncbi.nlm.nih.gov/sra and type PRJNA612437.
2. Click to "SRA Experiments"
3. Click on "Send Results to Run selector"
4. Download the SRR list by clicking 'Accession List' as SRR_Acc_List.txt

*NB: The data are all single-end reads*

In bash, download SRA files and convert them in fastq files:

```{bash}
while read name in list; do
	fastq-dump --split-spot $name
done < SRR_Acc_List.txt
```

## Rename fastq files

Change the SRR name to the name of the library

```{bash}
TODO when the data of CPV paper will be in NCBI
Also group needs to agree on name system for fastq files
```

## Run Bismark

For each fastq file, run the following command:

```{bash}
bash run_bismark.sh -1 <filename.fastq> -r </path/to/dir_fasta/> -o </name/output/directory/>
``` 


# Methylation call and DMR

Once Bismark has been run, cytosine report files for each methylation contexts are imported in methylKit R packages for further analysis.

Typical format of the bismark output file imported in methylKit:

The suffix of the file is `*_bismark_bt2.deduplicated.bismark.cov.gz.CHG_report_only_chr.txt` so it contains all the call for cytosines in CHG context, excluding the calls in organelles (chloroplast and mitochondria).

```
Chr4    1004    +       1       1       CHG     CAG
Chr4    1006    -       2       3       CHG     CTG
Chr4    1009    -       0       5       CHG     CCG
Chr4    1020    +       1       3       CHG     CCG
Chr4    1023    -       4       5       CHG     CCG
Chr4    1052    -       9       3       CHG     CCG
Chr4    1071    +       3       4       CHG     CAG
Chr4    1073    -       6       6       CHG     CTG
Chr4    1090    +       4       5       CHG     CCG
Chr4    1096    +       4       5       CHG     CTG

```

The columns represent chromosome, base position, strand position of the cytosine, number of methylated Cs, number unmethylated Cs, methylation context, and trinucleotide context.

Different functions were created to run the functions of methylKit in batch. These functions can be found in [scripts/functions_methylkit.R](functions_methylkit.R).

Here is described the pipeline used to process the methylation data in methylKit.

## Annotation Araport11

We need the last annotation of genes and TEs for Col-0. Use Araport11 annotation

Files downloaded from https://www.arabidopsis.org/download/list?dir=Genes%2FAraport11_genome_release

```{bash}
# Get genes
grep -P "\tgene\t" Araport11_GFF3_genes_transposons.201606.gff  > Araport11_GFF3_genes_only.gff

# Convert gff to bed format
gff2bed < Araport11_GFF3_genes_only.gff > Araport11_GFF3_genes_only_full.bed

# Keep only first 4 columns
cut -f1,2,3,4 Araport11_GFF3_genes_only_full.bed > Araport11_GFF3_genes_only.bed

# For TEs
grep "transposable_element" Araport11_GFF3_genes_transposons.201606.gff | wc -l
35090

# In comparison, there were 35082 transposable_element feature in TAIR10 annotation

grep "transposable_element" Araport11_GFF3_genes_transposons.201606.gff  > Araport11_GFF3_transposons.gff

# Convert gff to bed format
gff2bed < Araport11_GFF3_transposons.gff > Araport11_GFF3_transposons_full.bed

# Keep only first 4 columns
cut -f1,2,3,4 Araport11_GFF3_transposons_full.bed > Araport11_GFF3_transposons.bed


# Keep TEs bigger than 4 kb
cat Araport11_GFF3_transposons.bed | awk -F'\t' '$3-$2 >= 4000 {print $0}' > Araport11_GFF3_transposons_longer_4kb.bed

# Keep TEs smaller than 500 bp
cat Araport11_GFF3_transposons.bed | awk -F'\t' '$3-$2 < 500 {print $0}' > Araport11_GFF3_transposons_smaller_500bp.bed

```

## R libraries and functions

```{r,  message = FALSE}
####################################
#       Libraries and functions    #
####################################

library(scatterpie)
library(plyr)

# Load the R script functions_methylkit.R which contains wrap up functions to run in batch several
# methylKit functions
source("scripts/functions_methylkit.R")

####################################
#      Paths to DB directories     #
####################################

# Paths to database for the output files of methylKit
path_DB_CpG <- "/path/to/methylDB_CpG"
path_DB_CHG <- "/path/to/methylDB_CHG"
path_DB_CHH <- "/path/to/methylDB_CHH"

# Create a list of these 3 paths
list_DB_paths <- list(path_DB_CpG, path_DB_CHG, path_DB_CHH, path_DB_CX)

# Path containing cytosine report and bam files from bismark pipeline
path_bismark_files <- paste("/path/to/bismark/output/files/", sep = "")

####################################################
################# BED FILES ########################
####################################################

# Path to bed files for region analysis
bed_genes <- "Araport11_GFF3_genes_only.bed"

# Get coordinates of the genes body methylated and body methylated + intermediate methylated from Takuno et al., 2017 (https://academic.oup.com/mbe/article/34/6/1479/3059954)
# List sent by Takuno on 2019-06-24
bed_genes_BM <- "BM_gene_ID.bed"
bed_genes_BM_IM <- "BM_IM_gene_ID.bed"

# Analysis on cluster 5 and 6
# # Path to bed files for region analysis (see section 'Analysis of cluster 5 and 6' for details of these bed files)
bed_genes_cluster5 <- paste(path_bed, "cluster5_coordinates.bed", sep = "")
bed_genes_cluster6 <- paste(path_bed, "cluster6_coordinates.bed", sep = "")

# bed_genes_annotate <- paste(workdir, "Arabidopsis_thaliana.TAIR10.39.bed", sep="") # Version that was made from GTF (works with readTranscriptFeatures)

# All TEs
bed_TEs <- paste(path_bed, "Araport11_GFF3_transposons.bed", sep = "")

# TEs longer than 4 kb
bed_TEs_4kb <- paste(path_bed, "Araport11_GFF3_transposons_longer_4kb.bed", sep = "")

# TEs shorter than 500 bp
bed_TEs_500bp <- paste(path_bed, "Araport11_GFF3_transposons_smaller_500bp.bed", sep = "")


####################################################
################# ACCESSIONS FILES ########################
####################################################

# Path to file with accession information (several were used in the different analyses and they are all available in GitHub)
path_df_accessions <- "df_accessions.txt"

# Get information of the accessions and generate a table
# Order first the file to export so that the elements are ordered as the fastq files (3542_AA, 3542_AB, ...)
df_accessions <- read.table(path_df_accessions, header = TRUE, stringsAsFactors = TRUE)

# Order the accession as list.files() list the bismark cytosine report files
df_accessions <- order_df_accessions(df_accessions)

# I need to create an hybrid name otherwise the loading of the file won't respect the original order of the input bismark file
df_accessions$sample <- paste(df_accessions$library, df_accessions$name, sep = "_")

# Make a list of samples
list_samples <- as.list(as.vector(df_accessions$sample))

# Get list of treatments and reformat so that the first treatment is 0 (control should be 0 optimally)
# Here I put as example CMT2 allele but the variable used as treatment differ in different analysis
list_treatments <- as.vector(df_accessions$cmt2_allele)

# Change char to numeric to avoid bugs when using unite() function
list_treatments <- as.numeric(list_treatments)

# Vector of the 3 contexts analyzed
context <- c("CpG", "CHG", "CHH")
```


# Create methylKit objects

## Create methylRawListDB objects

The function `import_bismark_cytosine_report` will retrieve automatically the different cytosine report files generated by Bismark and will create flat database files, allowing to reduce RAM usage. 

```{r}
import_bismark_cytosine_report(path_bismark_files, list_DB_paths, list_samples, list_treatments)
```

## Load methylRawListDB objects

Once created, load methylRawListDB objects. The files won't actually be loaded but accessed in real time when needed.

```{r}
list_methylRawLists <- load_methylRawListDB(list_DB_paths, type = "", list_samples, list_treatments)
```

## Filter methylRawList raw

Keep only cytosine positions that have a define minimum coverage. This threshold is usually set at around 5 in most WGBS analyses but since our samples were sequenced at the minimum depth allowed by the sequencing facility, we defined a lower threshold (minimum 2). This approach is valid considering that we look at pattern across large genomic regions. We assumed we would catch any strong signal if any.

```{r}
filter_methylRawList(list_methylRawLists_raw)
```

## Load filtered methylRawListDB objects

```{r,  message = FALSE}
list_methylRawLists <- load_methylRawListDB(list_DB_paths, type = "filtered", list_samples, list_treatments)
```


# Subset genomic regions

We want now to analyze methylation patterns is specific genomic regions. For this, we need to subset our data and generate new DB flat files for the different regions.

## Subset data

```{r,  message = FALSE}
# Create subset for methylRawList
subset_methylObject(list_methylRawLists, list_DB_paths, bed_genes, "genes", "methylRaw")

subset_methylObject(list_methylRawLists, list_DB_paths, bed_TEs, "TEs", "methylRaw")

subset_methylObject(list_methylRawLists, list_DB_paths, bed_TEs_4kb, "TEs_4kb", "methylRaw")

```

## Load methylRaw subset data
```{r}
# Load subset data

# Load methylRawListDB objects (without filtering)
list_methylRawLists_genes <- load_methylRawListDB(list_DB_paths, type = "genes", list_samples, list_treatments)

list_methylRawLists_TEs <- load_methylRawListDB(list_DB_paths, type = "TEs", list_samples, list_treatments)

list_methylRawLists_TEs_4kb <- load_methylRawListDB(list_DB_paths, type = "TEs_4kb", list_samples, list_treatments)

```


# Methylation levels

We want first to visualize the methylation levels in different genomic regions. For this, we extract the weighted methylation levels

## Whole genome

```{r, fig.width=14, fig.height=5}
df_name <- "df_mean_filtered"
title <- "Weighted Methylation Level for genes"

get_df_wml(list_methylRawLists, path_DB, df_name)

load_df_wml(path_DB, df_name)

# Plot (use get() to pass the string name of the dataframe as a R object)
ggplot_all(get(df_name), title = title)
```


## Genes

```{r, fig.width=14, fig.height=5}
df_name <- "df_mean_genes"
title <- "Weighted Methylation Level for genes"

get_df_wml(list_methylRawLists_genes, path_DB, df_name)

load_df_wml(path_DB, df_name)

# Plot (use get() to pass the string name of the dataframe as a R object)
ggplot_all(df_mean_genes, title = title)
```

## All TEs

```{r, fig.width=14, fig.height=5}
df_name <- "df_mean_TEs"
title <- "Weighted Methylation Level for long TEs (>4 kb)"

get_df_wml(list_methylRawLists_TEs, path_DB, df_name)

load_df_wml(path_DB, df_name)
```

## Long TEs

```{r, fig.width=14, fig.height=5}
df_name <- "df_mean_TEs_4kb"
title <- "Weighted Methylation Level for long TEs (>4 kb)"

get_df_wml(list_methylRawLists_TEs_4kb, path_DB, df_name)

load_df_wml(path_DB, df_name)
```


# GWAS analysis


GWAS was performed as described in this repository: https://github.com/johanzi/gwas_gemma

The script `run_gwas_gemma.sh` can be downloaded from GitHub [gwas_gemma](https://github.com/johanzi/gwas_gemma) repository:

```{bash}
git clone https://github.com/johanzi/gwas_gemma
```


## Prepare VCF file

Check https://github.com/johanzi/gwas_gemma?tab=readme-ov-file#section-id-35

```{bash, eval=FALSE}
bcftools view -S list_accessions_to_keep.txt file.vcf.gz > subset_83.vcf

bcftools view -r Chr1,Chr2,Chr3,Chr4,Chr5 subset_80.vcf > subset_83_only_chr.vcf

bcftools view --min-ac=1 --max-alleles 2  subset_80_only_chr.vcf > subset_83_only_chr_biallelic_only_alt.vcf

vcftools --vcf subset_83_only_chr_biallelic_only_alt.vcf  \
			--minDP 3 --minGQ 25 --remove-indels --recode --recode-INFO-all \
			--out subset_83_only_chr_biallelic_only_alt_DP3_GQ25_wo_indels
```

The output file will be `subset_83_only_chr_biallelic_only_alt_DP3_GQ25_wo_singletons.recode.vcf.gz`.

## Prepare phenotye

Check https://github.com/johanzi/gwas_gemma?tab=readme-ov-file#section-id-139


## Run Gemma

The script should be executed for each context and each genomic region:

```{bash}

VCF="subset_83_only_chr_biallelic_only_alt_DP3_GQ25_wo_singletons.recode.vcf.gz"

# Genes
bash gwas_gemma/run_gwas_gemma.sh CpG_genes.tsv $VCF

bash gwas_gemma/run_gwas_gemma.sh CHG_genes.tsv $VCF

bash gwas_gemma/run_gwas_gemma.sh CHH_genes.tsv $VCF

# TEs
bash gwas_gemma/run_gwas_gemma.sh CpG_TEs.tsv $VCF

bash gwas_gemma/run_gwas_gemma.sh CHG_TEs.tsv $VCF

bash gwas_gemma/run_gwas_gemma.sh CHH_TEs.tsv $VCF

# long TEs
bash gwas_gemma/run_gwas_gemma.sh CpG_TEs_4kb.tsv $VCF

bash gwas_gemma/run_gwas_gemma.sh CHG_TEs_4kb.tsv $VCF

bash gwas_gemma/run_gwas_gemma.sh CHH_TEs_4kb.tsv $VCF

```

### GWAS genes

```{r}
dir_file="/path/to/file/"

file.name <- "CpG_genes.assoc.clean.txt"

path.file <- paste(dir_file, file.name, sep="")

SNP_significant <- GWAS_run(path.file, threshold_pvalue = "bonferroni")


file.name <- "CHG_genes.assoc.clean.txt"

path.file <- paste(dir_file, file.name, sep="")

SNP_significant <- GWAS_run(path.file, threshold_pvalue = "bonferroni")


file.name <- "CHH_genes.assoc.clean.txt"

path.file <- paste(dir_file, file.name, sep="")

SNP_significant <- GWAS_run(path.file, threshold_pvalue = "bonferroni")

```

### GWAS all TEs


```{r}
dir_file="/path/to/file/"

file.name <- "CpG_TEs.assoc.clean.txt"

path.file <- paste(dir_file, file.name, sep="")

SNP_significant <- GWAS_run(path.file, threshold_pvalue = "bonferroni")


file.name <- "CHG_TEs.assoc.clean.txt"

path.file <- paste(dir_file, file.name, sep="")

SNP_significant <- GWAS_run(path.file, threshold_pvalue = "bonferroni")


file.name <- "CHH_TEs.assoc.clean.txt"

path.file <- paste(dir_file, file.name, sep="")

SNP_significant <- GWAS_run(path.file, threshold_pvalue = "bonferroni")


```

### GWAS long TEs

```{r}

dir_file="/path/to/file/"

file.name <- "CpG_TEs_4kb.assoc.clean.txt"

path.file <- paste(dir_file, file.name, sep="")

SNP_significant <- GWAS_run(path.file, threshold_pvalue = "bonferroni")


file.name <- "CHG_TEs_4kb.assoc.clean.txt"

path.file <- paste(dir_file, file.name, sep="")

SNP_significant <- GWAS_run(path.file, threshold_pvalue = "bonferroni")


file.name <- "CHH_TEs_4kb.assoc.clean.txt"

path.file <- paste(dir_file, file.name, sep="")

SNP_significant <- GWAS_run(path.file, threshold_pvalue = "bonferroni")

```


# DMR analysis for the 3 genes



# Call allele status

```{bash, eval=FALSE}

# This script defines the step to retrieve the allele status for
# each CPV-SA accessions of the CMT2, ARABIDILLO-1, and VIM2 variants

################################################################################
# Packages/Sofwares requires
################################################################################

# vcf_melt (install with command "pip install PyVCF --user")

# bcftools

# samtools

################################################################################
########## Get VIM2 deletion, ARA1, and CMT2 status
################################################################################

# Use VCF file used for GWAS 

VCF="superVcf_19-07-04_cvis.vcf.b.gz_snps.vcf.b.gz"

#################################################################
# FBX5
#################################################################

# Get VCF data for SNP in FBX5
bcftools view -r Chr2:18513626 $VCF > Chr2_18513626.vcf

# Convert into vertical
vcf_melt Chr2_18513626.vcf > Chr2_18513626.melted.vcf 

# Keep only line with GQ >= 25 and DP >= 3
awk '$3>=25 && $4>=3 {print $0}' Chr2_18513626.melted.vcf > Chr2_18513626_GQ25_DP3.melted.vcf
 
# Accessions with alternative allele
awk '$2 == "1" {print $0}' Chr2_18513626_GQ25_DP3.melted.vcf | wc -l
84

awk '$2 == "1" {print $0}' Chr2_18513626_GQ25_DP3.melted.vcf | cut -f1 | sort - > FBX5_alt.txt
awk '$2 == "0" {print $0}' Chr2_18513626_GQ25_DP3.melted.vcf | cut -f1 | sort - > FBX5_ref.txt


awk -v OFS='\t' '{print $0,"FBX5_alt"}' FBX5_alt.txt > FBX5_alt_final.txt
awk -v OFS='\t' '{print $0,"FBX5_ref"}' FBX5_ref.txt > FBX5_ref_final.txt

cat FBX5_alt_final.txt FBX5_ref_final.txt > FBX5_allele_status.txt

rm FBX5_alt.txt FBX5_ref.txt FBX5_alt_final.txt FBX5_ref_final.txt 

#################################################################
# CMT2
#################################################################

bcftools view -r Chr4:10420088 $VCF > Chr4_10420088.vcf

# Convert into vertical
vcf_melt Chr4_10420088.vcf > Chr4_10420088.melted.vcf 

# Keep only line with GQ >= 25 and DP >= 3
awk '$3>=25 && $4>=3 {print $0}' Chr4_10420088.melted.vcf  > Chr4_10420088_GQ25_DP3.melted.vcf 

# Accessions with alternative allele
awk '$2 == "1" {print $0}' Chr4_10420088_GQ25_DP3.melted.vcf  | wc -l
65

awk '$2 == "1" {print $0}' Chr4_10420088_GQ25_DP3.melted.vcf  | cut -f1 | sort - > CMT2_alt.txt
awk '$2 == "0" {print $0}' Chr4_10420088_GQ25_DP3.melted.vcf  | cut -f1 | sort - > CMT2_ref.txt

awk -v OFS='\t' '{print $0,"CMT2_alt"}' CMT2_alt.txt > CMT2_alt_final.txt
awk -v OFS='\t' '{print $0,"CMT2_ref"}' CMT2_ref.txt > CMT2_ref_final.txt

cat CMT2_alt_final.txt CMT2_ref_final.txt > CMT2_allele_status.txt

rm CMT2_alt.txt CMT2_ref.txt CMT2_alt_final.txt CMT2_ref_final.txt 


#################################################################
# VIM2 deletion
#################################################################

# Considering that the VIM2 deletion is not present in the VCF file as it is a 
# structural variant and not a SNP, we need to assess the presence of the deletion
# based on read density at the deletion region

# coordinates of the deletion location (based on Cvi-0). The deletion is 2740 bp
# This region was defined by looking at read mapping in Cvi-0 and determine visually
# the beginning and end of the deletion
coordinates="chr1:24586731-24589471"

for i in mappedBAM/*bam; do
	name=$(basename $i | cut -d'.' -f1)
	nb_reads=$(samtools view $i $coordinates | wc -l)
	echo -e "${name}\t${nb_reads}" >> nb_reads_vim2_deletion.txt
done

cut -f2 nb_reads_vim2_deletion.txt | sort -n -
# Looking at the distribution of reads, it seems there is threshold at 14 reads. i
# Let's use 50 reads as the threshold to define that there is indeed a deletion

# Classify each sample based on nb of reads with threshold = 50
awk -v OFS="\t" '$2 <= 50 {print $1,$2,"deletion"} $2 > 50 {print $1,$2,"no_deletion"}' nb_reads_vim2_deletion.txt > nb_reads_vim2_deletion_status.txt

```

Note that for S3-9 (12849), reads support 50% of A and 50% of T, suggesting heterozygosity for the FBX5 SNP Chr2:18,513,626. We excluded this accession from the analysis based on this uncertainty.

# Allele distribution by population

```{bash, eval=FALSE}
########################################################
# Summary by population in SA for VIM2, FBX5, and CMT2
#########################################################

# 4073_M (Cvi-0 is included)
clean_file="/srv/biodata/dep_coupland/grp_hancock/VCF/santos_clean_2019-07-11.txt"

# File contains 190 accessions

#########################################################
# For FBX5

while read i; do 
	grep -w $i FBX5_allele_status.txt >> FBX5_allele_status_SA.txt
done < /srv/biodata/dep_coupland/grp_hancock/VCF/santos_clean_2019-07-11.txt

while read i; do
    seqID=$(echo "$i" | cut -f1)
    name=$(python /home/zicola/SCRIPTS/find_accession/find_accession.py /home/zicola/SCRIPTS/find_accession/updated_list_seqID_name.dict $seqID | cut -f2)
	population=$(echo $name | cut -d'-' -f1)
    echo -e "${i}\t${name}\t${population}"
done < FBX5_allele_status_SA.txt > FBX5_allele_status_SA_with_names.txt


# Replace FBX5_ref by 0 and FBX5_alt by 1
sed -i 's/FBX5_ref/0/' FBX5_allele_status_SA_with_names.txt
sed -i 's/FBX5_alt/1/' FBX5_allele_status_SA_with_names.txt

# 189 retrieved, accession 12849 has no GT assigned  

cd /srv/netscratch/dep_coupland/grp_hancock/mappedBAM/CVI
samtools tview  12849.sorted.bam  -p chr2:18513626 --reference /home/zicola/TAIR10_chr_Pt_Mt/TAIR10.fasta

# Weird as many reads support the ALT allele A
cd /srv/biodata/dep_coupland/grp_hancock/johan/allele_status

# Also present after filtering but no genotype given (second column
grep "12849" Chr2_18513626_GQ25_DP3.melted.vcf
12849   .                       ['q25'] Chr2    18513626        T       [A]             1       94957   84      2003


#########################################################
# For CMT2

while read i; do 
	grep -w $i CMT2_allele_status.txt >> CMT2_allele_status_SA.txt
done < /srv/biodata/dep_coupland/grp_hancock/VCF/santos_clean_2019-07-11.txt

# 190 accessions retrieved => OK


while read i; do
    seqID=$(echo "$i" | cut -f1)
    name=$(python /home/zicola/SCRIPTS/find_accession/find_accession.py /home/zicola/SCRIPTS/find_accession/updated_list_seqID_name.dict $seqID | cut -f2)
	population=$(echo $name | cut -d'-' -f1)
    echo -e "${i}\t${name}\t${population}"
done < CMT2_allele_status_SA.txt > CMT2_allele_status_SA_with_names.txt


# Replace CMT2_ref by 0 and CMT2_alt by 1
sed -i 's/CMT2_ref/0/' CMT2_allele_status_SA_with_names.txt
sed -i 's/CMT2_alt/1/' CMT2_allele_status_SA_with_names.txt


#########################################################
# For VIM2

while read i; do 
	foo=$(grep -w $i nb_reads_vim2_deletion_all_with_name_clean.txt | cut -f1,3,4)
	population=$(echo "$foo" | cut -f3 | cut -d'-' -f1)
	echo -e "${foo}\t${population}"
done < /srv/biodata/dep_coupland/grp_hancock/VCF/santos_clean_2019-07-11.txt > VIM2_allele_status_SA_with_names.txt

# 190 accessions retrieved => OK

# Replace no_deletion by 0 and deletion by 1
sed -i 's/no_deletion/0/' VIM2_allele_status_SA_with_names.txt
sed -i 's/deletion/1/' VIM2_allele_status_SA_with_names.txt

# Integrate that with coordinates data

# Reference files
/netscratch/dep_coupland/grp_hancock/Celia/Experiments/newBronson/coord_genotype.txt

# Get first 3 first rows
cut -f1,2,3 /netscratch/dep_coupland/grp_hancock/Celia/Experiments/newBronson/coord_genotype.txt > coord_populations_SA.txt
```


# Map allele distribution by population

```{r}
#install.packages("scatterpie")
#install.packages("ggmap")
#install.packages("maps")

library(scatterpie)
library(ggmap)
library(maps)
library(plyr)

# As input file, I need longitude, latitude, population name, frequency of ancestral allele, frequency of derived allele, gene name (optional if only 1 gene), 
# the radius to define the size of the pie charts on the map (use total_individuals  * 0.005 / 10)
```

## Coordinate file 

```{r}
# Replace Cratera by SCratera in bash
# Modify header
# Data from SantoCoordinates.csv files in Google Drive Hancock lab
# There are coordinates for 31 populations

# I chose arbitrarily S11-rav1	-25.076404	17.114951 as S11 population and S24-1	-25.076925	17.105766 as S24
# population, remove the other S11 and S24 from the file

df_coordinates <- read.table("data/coord_populations_SA.txt", header=TRUE)
names(df_coordinates) <- c("population","long","lat")
```

## VIM2 distribution

```{r}

df_vim2 <- read.table("data/VIM2_allele_status_SA_with_names.txt", header=FALSE)
names(df_vim2) <- c("seqID","GT","accession","population")

df_vim2$population <- as.factor(df_vim2$population )

# Summarize by population
df_vim2_summary <- plyr::ddply(df_vim2, .(population), summarise, total=length(population), freq_derived=sum(GT)/total, freq_derived=(sum(GT)/total), freq_ancestral=(1-freq_derived), radius=(total*0.005/10))

# Merge with coordinate, somehow I get duplicated rows. Use unique()
df_vim2_coord <- unique(merge(df_vim2_summary, df_coordinates, by="population"))

world <- map_data("world")
SA <- world[world$long > -30 & world$long < -20 & world$lat > 10 & world$lat < 20,]

ggplot(SA, aes(long, lat)) +
  geom_map(map = world, aes(map_id = region), fill = NA, color = "black") +
  coord_quickmap() +
  xlim(-25.1, -25.01) +
  ylim(17.09, 17.135) +
  theme(plot.background = element_rect(fill = "transparent"), panel.background = element_rect(fill = "transparent"), panel.grid.minor = element_blank(), panel.grid.major = element_blank(), axis.line.x = element_line(color = "black", size = 0.5), axis.line.y = element_line(color = "black", size = 0.5)) +
  xlab("Longitude") +
  ylab("Latitude") +
  geom_scatterpie(aes(x = long, y = lat, r = radius, group = population), data = df_vim2_coord, cols = c("freq_derived","freq_ancestral"), sorted_by_radius = TRUE, alpha = .5) +
  labs(fill = "VIM2 alleles") +
  scale_fill_manual(values = c("coral2", "turquoise4")) +
  theme(axis.title.x = element_text(size = 16), axis.title.y = element_text(size = 16)) +
  geom_scatterpie_legend(df_vim2_coord$radius, x = -25.03, y = 17.124, n = 4, labeller = function(x) 10 * x / 0.005)

```

![](images/VIM2_allele_map.png)

## CMT2 distribution

```{r}

df_cmt2 <- read.table("data/CMT2_allele_status_SA_with_names.txt", header=FALSE)
names(df_cmt2) <- c("seqID","GT","accession","population")

# Summarize by population
df_cmt2_summary <- ddply(df_cmt2, .(population), summarise, total=length(population), freq_derived=(sum(GT)/total), freq_ancestral=(1-freq_derived), radius=(total*0.005/10))

# Merge with coordinate, somehow I get duplicated rows. Use unique()
df_cmt2_coord <- merge(df_cmt2_summary, df_coordinates, by="population")

world <- map_data("world")
SA <- world[world$long > -30 & world$long < -20 & world$lat > 10 & world$lat < 20,]

ggplot(SA, aes(long, lat)) +
  geom_map(map = world, aes(map_id = region), fill = NA, color = "black") +
  coord_quickmap() +
  xlim(-25.1, -25.01) +
  ylim(17.09, 17.135) +
  theme(plot.background = element_rect(fill = "transparent"), panel.background = element_rect(fill = "transparent"), panel.grid.minor = element_blank(), panel.grid.major = element_blank(), axis.line.x = element_line(color = "black", size = 0.5), axis.line.y = element_line(color = "black", size = 0.5)) +
  xlab("Longitude") +
  ylab("Latitude") +
  geom_scatterpie(aes(x = long, y = lat, r = radius, group = population), data = df_cmt2_coord, cols = c("freq_derived","freq_ancestral"), sorted_by_radius = TRUE, alpha = .5) +
  labs(fill = "CMT2 alleles") +
  scale_fill_manual(values = c("turquoise4", "coral2")) +
  theme(axis.title.x = element_text(size = 16), axis.title.y = element_text(size = 16)) +
  geom_scatterpie_legend(df_cmt2_coord$radius, x = -25.03, y = 17.124, n = 4, labeller = function(x) 10 * x / 0.005)

```

![](images/CMT2_allele_map.png)

## FBX5 distribution

```{r}

df_fbx5 <- read.table("data/FBX5_allele_status_SA_with_names.txt", header=FALSE)
names(df_fbx5) <- c("seqID","GT","accession","population")

# Summarize by population
df_fbx5_summary <- ddply(df_fbx5, .(population), summarise, total=length(population), freq_derived=(sum(GT)/total), freq_ancestral=(1-freq_derived), radius=(total*0.005/10))

# Merge with coordinate, somehow I get duplicated rows. Use unique()
df_fbx5_coord <- unique(merge(df_fbx5_summary, df_coordinates, by="population"))

world <- map_data("world")
SA <- world[world$long > -30 & world$long < -20 & world$lat > 10 & world$lat < 20,]

ggplot(SA, aes(long, lat)) +
  geom_map(map = world, aes(map_id = region), fill = NA, color = "black") +
  coord_quickmap() +
  xlim(-25.1, -25.01) +
  ylim(17.09, 17.135) +
  theme(plot.background = element_rect(fill = "transparent"), panel.background = element_rect(fill = "transparent"), panel.grid.minor = element_blank(), panel.grid.major = element_blank(), axis.line.x = element_line(color = "black", size = 0.5), axis.line.y = element_line(color = "black", size = 0.5)) +
  xlab("Longitude") +
  ylab("Latitude") +
  geom_scatterpie(aes(x = long, y = lat, r = radius, group = population), data = df_fbx5_coord, cols = c("freq_derived","freq_ancestral"), sorted_by_radius = TRUE, alpha = .5) +
  labs(fill = "FBX5 alleles") +
  scale_fill_manual(values = c("coral2","turquoise4")) +
  theme(axis.title.x = element_text(size = 16), axis.title.y = element_text(size = 16)) +
  geom_scatterpie_legend(df_fbx5_coord$radius, x = -25.03, y = 17.124, n = 4, labeller = function(x) 10 * x / 0.005)

```

![](images/FBX5_allele_map.png)

## Plot diagram VIM2

```{r}
df_vim2_coord$population_nb <- paste(df_vim2_coord$population, " n=", df_vim2_coord$total, sep="")

# Remove Cvi
df <- df_vim2_coord[!(df_vim2_coord$population=="Cvi"),]

# Order accesstion by longitude
df$population_nb <- factor(df$population_nb, levels = df$population_nb[order(df$long)])

ggplot(data = df, aes(population_nb, freq_derived)) +
  ggtitle("VIM2 deletion frequency") +
  geom_bar(aes(x = population_nb, y = freq_derived), stat = "identity", colour = "black", fill = "grey") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  ylab("Deletion frequency") +
  xlab("Population") +
  scale_y_continuous(labels = scales::percent)


```


![](images/VIM2_deletion_frequency.png)



## Plot diagram CMT2

```{r}

df_cmt2_coord$population_nb <- paste(df_cmt2_coord$population, " n=", df_cmt2_coord$total, sep="")

# Remove Cvi
df <- df_cmt2_coord[!(df_cmt2_coord$population=="Cvi"),]

# Order accesstion by longitude
df$population_nb <- factor(df$population_nb, levels = df$population_nb[order(df$long)])

ggplot(data = df, aes(population_nb, freq_derived)) +
  ggtitle("Derived CMT2 allele frequency") +
  geom_bar(aes(x = population_nb, y = freq_derived), stat = "identity", colour = "black", fill = "grey") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  ylab("Derived allele frequency") +
  xlab("Population") +
  scale_y_continuous(labels = scales::percent)


```

![](images/CMT2_deletion_frequency.png)

## Plot diagram FBX5

```{r}
# Create new variable which concatenat population name and number of accessions
df_fbx5_coord$population_nb <- paste(df_fbx5_coord$population, " n=", df_fbx5_coord$total, sep="")

# Remove Cvi
df <- df_fbx5_coord[!(df_fbx5_coord$population=="Cvi"),]

# Order accesstion by longitude
df$population_nb <- factor(df$population_nb, levels = df$population_nb[order(df$long)])

ggplot(data = df, aes(population_nb, freq_derived)) +
  ggtitle("Derived ARABIDILLO-1 allele frequency") +
  geom_bar(aes(x = population_nb, y = freq_derived), stat = "identity", colour = "black", fill = "grey") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  ylab("Derived allele frequency") +
  xlab("Population") +
  scale_y_continuous(labels = scales::percent)

```


![](images/FBX5_deletion_frequency.png)

#. 
# Analysis DNA methylation in SAIL and SALK fbx5 and cmt2 mutants


## Samples

Note that we use here ARA1 (short for ARABIDILLO-1) in place of FBX5. We changed this in the manuscript since ARA1 is already allocated to another gene (AT4G16130) and FBX5 was the first reference for the gene AT2G44900.

ara12 stands for the double mutant ARABIDILLO-1/FBX5 (AT2G44900) and ARABIDILLO-2 (	
AT3G60350). Details on the SRA for each library is available on Supplementary table 1 of the paper.

| name          | library | sample               | pool      |
|---------------|---------|----------------------|-----------|
| ara12_I       | 4373_A  | 4373_A_ara12_I       | ara12     |
| ara12_II      | 4373_B  | 4373_B_ara12_II      | ara12     |
| ara12_III     | 4373_C  | 4373_C_ara12_III     | ara12     |
| ara1-SALK_I   | 4373_D  | 4373_D_ara1-SALK_I   | ara1-SALK |
| ara1-SALK_II  | 4373_E  | 4373_E_ara1-SALK_II  | ara1-SALK |
| ara1-SALK_III | 4373_F  | 4373_F_ara1-SALK_III | ara1-SALK |
| ARA1-OE_I     | 4373_G  | 4373_G_ARA1-OE_I     | ARA1-OE   |
| ARA1-OE_II    | 4373_H  | 4373_H_ARA1-OE_II    | ARA1-OE   |
| ARA1-OE_III   | 4373_I  | 4373_I_ARA1-OE_III   | ARA1-OE   |
| ara1-SAIL_I   | 4373_J  | 4373_J_ara1-SAIL_I   | ara1-SAIL |
| ara1-SAIL_II  | 4373_K  | 4373_K_ara1-SAIL_II  | ara1-SAIL |
| ara1-SAIL_III | 4373_L  | 4373_L_ara1-SAIL_III | ara1-SAIL |
| cmt2-5_I      | 4373_M  | 4373_M_cmt2-5_I      | cmt2-5    |
| cmt2-5_II     | 4373_N  | 4373_N_cmt2-5_II     | cmt2-5    |
| cmt2-5_III    | 4373_O  | 4373_O_cmt2-5_III    | cmt2-5    |
| Col-3_I       | 4373_P  | 4373_P_Col-3_I       | Col-3     |
| Col-3_II      | 4373_Q  | 4373_Q_Col-3_II      | Col-3     |
| Col-3_III     | 4373_R  | 4373_R_Col-3_III     | Col-3     |
| Col-0_I       | 4373_S  | 4373_S_Col-0_I       | Col-0     |
| Col-0_II      | 4373_T  | 4373_T_Col-0_II      | Col-0     |
| Col-0_III     | 4373_U  | 4373_U_Col-0_III     | Col-0     |
| Cvi-0_I       | 4373_V  | 4373_V_Cvi-0_I       | Cvi-0     |
| Cvi-0_II      | 4373_W  | 4373_W_Cvi-0_II      | Cvi-0     |
| Cvi-0_III     | 4373_X  | 4373_X_Cvi-0_III     | Cvi-0     |


## Create methylKit objects

## Create methylRawListDB objects

```{r}
import_bismark_cytosine_report(path_bismark_files, list_DB_paths, list_samples, list_treatments)
```

## Load methylRawListDB objects

```{r,  message = FALSE}
# Load methylRawListDB objects (without filtering)
list_methylRawLists_raw <- load_methylRawListDB(list_DB_paths, type="raw", list_samples, list_treatments)

```

## Filter methylRawList raw

```{r}
filter_methylRawList(list_methylRawLists_raw)
```

## Load filtered methylRawListDB objects
```{r,  message = FALSE}
list_methylRawLists <- load_methylRawListDB_wo_CX(list_DB_paths, type="filtered", list_samples, list_treatments)
```


## Subset genomic regions

## Subset data

Get data for each regions. In this case we select TEs, genic and intergenic regions.
```{r,  message = FALSE}
# Create subset for methylRawList
subset_methylObject(list_methylRawLists, list_DB_paths, bed_genes, "genes", "methylRaw")

subset_methylObject(list_methylRawLists, list_DB_paths, bed_TEs, "TEs", "methylRaw")

subset_methylObject(list_methylRawLists, list_DB_paths, bed_TEs_4kb, "TEs_4kb", "methylRaw")
```

## Load methylRaw subset data

```{r}

# Load methylRawListDB objects (without filtering)
list_methylRawLists_genes <- load_methylRawListDB(list_DB_paths, type="genes", list_samples, list_treatments)

list_methylRawLists_TEs <- load_methylRawListDB(list_DB_paths, type="TEs", list_samples, list_treatments)

list_methylRawLists_TEs_4kb <- load_methylRawListDB(list_DB_paths, type="TEs_4kb", list_samples, list_treatments)

```


## mCG in long TEs for FBX5 mutants

```{r}

df_name <- "df_mean_TEs_4kb"
title <- "Weighted Methylation Level for long TEs (>4 kb)"

get_df_wml(list_methylRawLists_TEs_4kb, path_DB, df_name)

load_df_wml(path_DB, df_name)


# Merge dataframes of methylation levels and df_accessions to get detailed information about dataset
df_mean <- merge(get(df_name), df_accessions, by="sample")


df_mean_subset <- df_mean %>% filter(context=="CpG") %>% filter(!pool %in% c("cmt2-5","cmt2","S27-204","Cvi-0"))

order_pool <- c("Col-0","ara1-SALK","ARA1-OE","Col-3","ara1-SAIL","ara12")

df_mean_subset$pool <- factor(df_mean_subset$pool , levels=order_pool, ordered=TRUE)

# Rename samples

ggplot(data=df_mean_subset, aes(x=pool, y=percent_methylation, group=pool)) + 
  geom_boxplot(outlier.size=1) +
  geom_jitter(height=.05, width=.05, size=1) +  
  theme_bw() +
  ylab("% methylated cytosines (CG)") +
  ggtitle("CpG methylation in long TEs") +
  theme(plot.title = element_text(hjust = 0.5)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  xlab("") + scale_y_continuous(limits=c(78, 90), breaks=seq(78,90,2)) +
  scale_x_discrete(labels=c("Col-0","SALK_082977","FBX5-OE","Col-3","SAIL_190_D02","SAILD_190_D02/arabidillo-2"))

```

![](images/mCG_long_TEs_fbx5_mutants.png)

## mCHG in long TEs for FBX5 mutants

```{r}

df_name <- "df_mean_TEs_4kb"
title <- "Weighted Methylation Level for long TEs (>4 kb)"

get_df_wml(list_methylRawLists_TEs_4kb, path_DB, df_name)

load_df_wml(path_DB, df_name)


# Merge dataframes of methylation levels and df_accessions to get detailed information about dataset
df_mean <- merge(get(df_name), df_accessions, by="sample")


df_mean_subset <- df_mean %>% filter(context=="CHG") %>% filter(!pool %in% c("cmt2-5","cmt2","S27-204","Cvi-0"))

order_pool <- c("Col-0","ara1-SALK","ARA1-OE","Col-3","ara1-SAIL","ara12")

df_mean_subset$pool <- factor(df_mean_subset$pool , levels=order_pool, ordered=TRUE)

# Rename samples

ggplot(data=df_mean_subset, aes(x=pool, y=percent_methylation, group=pool)) + 
  geom_boxplot(outlier.size=1) +
  geom_jitter(height=.05, width=.05, size=1) +  
  theme_bw() +
  ylab("% methylated cytosines (CHG)") +
  ggtitle("CHG methylation in long TEs") +
  theme(plot.title = element_text(hjust = 0.5)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  xlab("") + scale_y_continuous(limits=c(40, 48), breaks=seq(40,48,2)) +
  scale_x_discrete(labels=c("Col-0","SALK_082977","FBX5-OE","Col-3","SAIL_190_D02","SAILD_190_D02/arabidillo-2"))

```

![](images/fbx5_mCHG_longTEs.png)
## mCHH in long TEs for FBX5 mutants

```{r}

df_name <- "df_mean_TEs_4kb"
title <- "Weighted Methylation Level for long TEs (>4 kb)"

get_df_wml(list_methylRawLists_TEs_4kb, path_DB, df_name)

load_df_wml(path_DB, df_name)


# Merge dataframes of methylation levels and df_accessions to get detailed information about dataset
df_mean <- merge(get(df_name), df_accessions, by="sample")


df_mean_subset <- df_mean %>% filter(context=="CHH") %>% filter(!pool %in% c("cmt2-5","cmt2","S27-204","Cvi-0"))

order_pool <- c("Col-0","ara1-SALK","ARA1-OE","Col-3","ara1-SAIL","ara12")

df_mean_subset$pool <- factor(df_mean_subset$pool , levels=order_pool, ordered=TRUE)


ggplot(data=df_mean_subset, aes(x=pool, y=percent_methylation, group=pool)) + 
  geom_boxplot(outlier.size=1) +
  geom_jitter(height=.05, width=.05, size=1) +  
  theme_bw() +
  ylab("% methylated cytosines (CHH)") +
  ggtitle("CHH methylation in long TEs") +
  theme(plot.title = element_text(hjust = 0.5)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  xlab("") + scale_y_continuous(limits=c(8, 14), breaks=seq(8,14,2)) +
  scale_x_discrete(labels=c("Col-0","SALK_082977","FBX5-OE","Col-3","SAIL_190_D02","SAILD_190_D02/arabidillo-2"))

```

![](images/fbx5_mCHH_long_TEs.png)
## Statistical tests

Check significance of difference between Col-0 and ara1-SALK and ARA1-OE, and Col-3 and ara12 and ara1-SAIL

### Col-0 background

#### mCG

```{r}

require(onewaytests)
require(multcomp)

df <- df_mean %>% filter(context=="CpG") %>% filter(pool %in% c("Col-0","ara1-SALK","ARA1-OE"))

bartlett.test(percent_methylation~pool, data=df)

lm1 <- aov(percent_methylation ~ pool, data=df)
summary(glht(lm1, linfct=mcp(pool="Tukey"), alternative="two.sided"))

```

Bartlett test of homogeneity of variances

data:  percent_methylation by pool
Bartlett's K-squared = 2.4966, df = 2, p-value = 0.287


	 Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: aov(formula = percent_methylation ~ pool, data = df)

Linear Hypotheses:
                         Estimate Std. Error t value Pr(>|t|)    
ara1-SALK - ARA1-OE == 0   5.0455     0.5667   8.903  < 0.001 ***
Col-0 - ARA1-OE == 0       1.2969     0.5667   2.288  0.13379    
Col-0 - ara1-SALK == 0    -3.7486     0.5667  -6.614  0.00127 ** 

#### mCHG

```{r}

require(onewaytests)
require(multcomp)

df <- df_mean %>% filter(context=="CHG") %>% filter(pool %in% c("Col-0","ara1-SALK","ARA1-OE"))

bartlett.test(percent_methylation~pool, data=df)

lm1 <- aov(percent_methylation ~ pool, data=df)
summary(glht(lm1, linfct=mcp(pool="Tukey"), alternative="two.sided"))

```

Bartlett test of homogeneity of variances

data:  percent_methylation by pool
Bartlett's K-squared = 0.29114, df = 2, p-value = 0.8645


	 Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: aov(formula = percent_methylation ~ pool, data = df)

Linear Hypotheses:
                         Estimate Std. Error t value Pr(>|t|)  
ara1-SALK - ARA1-OE == 0   1.8133     0.7679   2.361   0.1218  
Col-0 - ARA1-OE == 0      -0.2800     0.7679  -0.365   0.9302  
Col-0 - ara1-SALK == 0    -2.0933     0.7679  -2.726   0.0768 .

#### mCHH

```{r}

require(onewaytests)
require(multcomp)

df <- df_mean %>% filter(context=="CHH") %>% filter(pool %in% c("Col-0","ara1-SALK","ARA1-OE"))

bartlett.test(percent_methylation~pool, data=df)

lm1 <- aov(percent_methylation ~ pool, data=df)
summary(glht(lm1, linfct=mcp(pool="Tukey"), alternative="two.sided"))

```

	Bartlett test of homogeneity of variances

data:  percent_methylation by pool
Bartlett's K-squared = 0.28809, df = 2, p-value = 0.8658


	 Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: aov(formula = percent_methylation ~ pool, data = df)

Linear Hypotheses:
                         Estimate Std. Error t value Pr(>|t|)  
ara1-SALK - ARA1-OE == 0  -0.5501     0.3617  -1.521   0.3469  
Col-0 - ARA1-OE == 0      -1.1019     0.3617  -3.046   0.0511 .
Col-0 - ara1-SALK == 0    -0.5518     0.3617  -1.525   0.3450  


### Col-3 background

#### mCG

```{r}

require(onewaytests)
require(multcomp)

df <- df_mean %>% filter(context=="CpG") %>% filter(pool %in% c("Col-3","ara1-SAIL","ara12"))

bartlett.test(percent_methylation~pool, data=df)

lm1 <- aov(percent_methylation ~ pool, data=df)
summary(glht(lm1, linfct=mcp(pool="Tukey"), alternative="two.sided"))

```


	Bartlett test of homogeneity of variances

data:  percent_methylation by pool
Bartlett's K-squared = 0.77576, df = 2, p-value = 0.6785


	 Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: aov(formula = percent_methylation ~ pool, data = df)

Linear Hypotheses:
                       Estimate Std. Error t value Pr(>|t|)    
ara12 - ara1-SAIL == 0   1.3206     0.2585   5.108   0.0052 ** 
Col-3 - ara1-SAIL == 0  -4.3065     0.2585 -16.657   <0.001 ***
Col-3 - ara12 == 0      -5.6272     0.2585 -21.765   <0.001 ***

#### mCHG

```{r}

require(onewaytests)
require(multcomp)

df <- df_mean %>% filter(context=="CHG") %>% filter(pool %in% c("Col-3","ara1-SAIL","ara12"))

bartlett.test(percent_methylation~pool, data=df)

lm1 <- aov(percent_methylation ~ pool, data=df)
summary(glht(lm1, linfct=mcp(pool="Tukey"), alternative="two.sided"))

```

	Bartlett test of homogeneity of variances

data:  percent_methylation by pool
Bartlett's K-squared = 0.056846, df = 2, p-value = 0.972


	 Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: aov(formula = percent_methylation ~ pool, data = df)

Linear Hypotheses:
                       Estimate Std. Error t value Pr(>|t|)  
ara12 - ara1-SAIL == 0   0.3367     0.7415   0.454   0.8945  
Col-3 - ara1-SAIL == 0  -2.6067     0.7415  -3.516   0.0295 *
Col-3 - ara12 == 0      -2.9433     0.7415  -3.970   0.0173 *

#### mCHH

```{r}

require(onewaytests)
require(multcomp)

df <- df_mean %>% filter(context=="CHH") %>% filter(pool %in% c("Col-3","ara1-SAIL","ara12"))

bartlett.test(percent_methylation~pool, data=df)

lm1 <- aov(percent_methylation ~ pool, data=df)
summary(glht(lm1, linfct=mcp(pool="Tukey"), alternative="two.sided"))

```

Bartlett test of homogeneity of variances

data:  percent_methylation by pool
Bartlett's K-squared = 0.46264, df = 2, p-value = 0.7935


	 Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: aov(formula = percent_methylation ~ pool, data = df)

Linear Hypotheses:
                       Estimate Std. Error t value Pr(>|t|)
ara12 - ara1-SAIL == 0  -0.9421     0.7153  -1.317    0.437
Col-3 - ara1-SAIL == 0  -1.0532     0.7153  -1.472    0.367
Col-3 - ara12 == 0      -0.1111     0.7153  -0.155    0.987


## mCHH in long TEs for cmt2-5 mutants

```{r}

df_name <- "df_mean_TEs_4kb"
title <- "Weighted Methylation Level for long TEs (>4 kb)"

get_df_wml(list_methylRawLists_TEs_4kb, path_DB, df_name)

load_df_wml(path_DB, df_name)

# Merge dataframes of methylation levels and df_accessions to get detailed information about dataset
df_mean <- merge(get(df_name), df_accessions, by="sample")

df_mean_subset <- df_mean %>% filter(pool %in% c("cmt2-5","Col-3")) %>% filter(context=="CHH")

order_pool <- c("Col-3","cmt2-5")

df_mean_subset$pool <- factor(df_mean_subset$pool , levels=order_pool, ordered=TRUE)


ggplot(data=df_mean_subset[(df_mean_subset$context=="CHH"),], aes(x=pool, y=percent_methylation, group=pool)) + 
  geom_boxplot(outlier.size=1) +
  geom_jitter(height=.05, width=.05, size=1) +  
  theme_bw() +
  ylab("% of methylated cytosines (CHH)") +
  ggtitle("CpG methylation whole genome") +
  theme(plot.title = element_text(hjust = 0.5)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  xlab("") + scale_y_continuous(limits=c(0, 14), breaks=seq(0,14,2)) +
  scale_x_discrete(labels=c("Col-3","cmt2-5 SAIL"))

```

![](images/mCHH_long_TE_Col3_cmt25.png)

### Statistical test

```{r}
# Check variance
bartlett.test(percent_methylation~pool, data = df_mean_subset)
#qqnorm(df_mean_subset$percent_methylation); qqline(df_mean_subset$percent_methylation)

# Variance and normality OK

# Alt Hypothesis is ara1 mCG > Col-0 mCG 
with(df_mean_subset, t.test(percent_methylation[pool=="Col-3"], percent_methylation[pool=="cmt2-5"], alternative="two.sided", var.equal=TRUE))

```

Bartlett test of homogeneity of variances

data:  percent_methylation by pool
Bartlett's K-squared = 2.337, df = 1, p-value = 0.1263


	Two Sample t-test

data:  percent_methylation[pool == "Col-3"] and percent_methylation[pool == "cmt2-5"]
t = 19.682, df = 4, p-value = 3.93e-05
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
  8.07735 10.73048
sample estimates:
mean of x mean of y 
 11.26492   1.86100 


#.

# Analysis TE expression

```{bash, eval=FALSE}

echo "###############################################################################"
echo "STEP I: Mapping RNA-seq data as first step of RepEnrich2"
echo "###############################################################################"
# bowtie2 in /opt/share/software/bin/bowtie2
# version 2.2.8

fastq_dir="/srv/biodata/irg/grp_hancock/NGS_data/GC_4559/raw_fastq/final/trimmed_reads"
bowtie_index="~/TAIR10_Chr_no_Pt_Mt/bowtie2_index/TAIR10_bowtie2"
output_dir="/srv/netscratch/irg/grp_hancock/johan/repenrich2_pipeline/output_4559"

for i in ${fastq_dir}/*.fastq.gz; do
  name_fastq=$(basename $i | cut -d. -f1)
  # Create a directory to store the output bam file
  if [ ! -d ${output_dir}/${name_fastq} ]; then
    mkdir  ${output_dir}/${name_fastq}
    echo "bowtie2 -q -p 16 -x $bowtie_index -U $i | samtools view -bS - > ${output_dir}/${name_fastq}/${name_fastq}.bam"
    bowtie2 -q -p 16 -x $bowtie_index -U $i | samtools view -bS - > ${output_dir}/${name_fastq}/${name_fastq}.bam
  else
    echo "${output_dir}/${name_fastq} already exists"
  fi
done

echo "###############################################################################"
echo "STEP II: Split uniquely mapped and multimapping reads"
echo "###############################################################################"

repenrich2_index="/srv/netscratch/irg/grp_hancock/johan/repenrich2_pipeline/repenrich2_araport11"
script_repenrich2="/home/zicola/SCRIPTS/analysis_RNA-seq_GC4559_4568_4623/analysis_RepEnrich/RepEnrich2"


# Loop over created directories in step I
for dir in ${output_dir}/*/; do
name_sample=$(basename $dir)
  if [ -e ${dir}${name_sample}_multimap.fastq ] && [ -e ${dir}${name_sample}_unique.bam ] && [ -e ${dir}${name_sample}_multimap_filtered.bam ]; then
    echo "${dir}${name_sample}_unique.bam already exists"
    echo "${dir}${name_sample}_multimap.fastq already exists"
    echo "${dir}${name_sample}_multimap_filtered.bam already exists"
  else
    name_sample=$(basename $dir)
    echo "python ${script_repenrich2}/RepEnrich2_subset.py ${dir}${name_sample}.bam 30 ${dir}${name_sample} --pairedend FALSE"
    python ${script_repenrich2}/RepEnrich2_subset.py ${dir}${name_sample}.bam 30 ${dir}${name_sample} --pairedend FALSE
  fi
done


echo "###############################################################################"
echo "STEP III: Mapping to TEs"
echo "###############################################################################"

te_annotation="/home/zicola/SCRIPTS/analysis_RNA-seq_GC4559_4568_4623/analysis_RepEnrich/araport11_TE_annotation_fixed.txt"

# When the index will be renamed
for dir in ${output_dir}/*/; do
  name_sample=$(basename $dir)
  if [ ! -e ${dir}${name_sample}_fraction_counts.txt ]; then
    echo "python ${script_repenrich2}/RepEnrich2.py $te_annotation ${dir} ${name_sample} ${repenrich2_index} ${dir}${name_sample}_multimap.fastq ${dir}${name_sample}_unique.bam --is_bed TRUE --cpus 16 --pairedend FALSE"
    python ${script_repenrich2}/RepEnrich2.py $te_annotation ${dir} ${name_sample} ${repenrich2_index} ${dir}${name_sample}_multimap.fastq ${dir}${name_sample}_unique.bam --is_bed TRUE --cpus 16 --pairedend FALSE
  else
    echo "${dir}${name_sample}_fraction_counts.txt already exists"
  fi
done

```


```{bash, eval=FALSE}
nohup bash repenrich2_batch_4559.sh &
```

#.

# RNA-seq library preparation

We generated leaf transcriptomes for 97 Santo Antão accessions, including 11 accessions with three biological replicates. Rosette leaves from 4-true leaves (20 DAG) were collected between ZT3 and ZT6 and flash-frozen into liquid nitrogen. Samples were ground in 2 ml Eppendorf tubes containing one tungsten carbide ball in a TissueLyser II (Qiagen). An aliquot of about 20 mg of powder was transferred into a 96 well plate, and total RNA was prepared with the NucleoMag® 96 RNA kit (Macherey Nagel). Libraries were prepared with the NEBNext Ultra™ Directional RNA Library Prep Kit for Illumina sequencing (New England Biolabs). Approximately about 7 million reads of 150 bp single-end reads were generated on the Illumina sequencer HiSeq3000. The adaptors were trimmed using Cutadapt (parameters -m 20 -q 35) (Martin 2011). Reads were mapped on TAIR10 reference genome and Araport11 gene annotation using HISAT2 (v2.2.0) (Kim et al. 2019, 2). The read count was performed with HTSeq (v0.12.4) (Anders et al. 2015). Differential expression analysis was performed in R using the DESeq2 package (v1.28.1) (Love et al. 2014).

137 samples
98 accessions (97 SA + Col-0)
19 samples in 3 replicates (57 samples) + 1 sample in duplicate (S4-B3-14, 4623_AR and 4623_BF)
CMT2stop = 37/98
FBX5stop = 42/98
VIM2del = 45/98


| library | sample           | seqID   | FBX5 | CMT2 | VIM2 |
|---------|------------------|---------|------|------|------|
| 4559_AA | S11-45           | 27175   | 0    | 1    | 0    |
| 4559_AB | S11-63           | 15675   | 1    | 0    | 1    |
| 4559_AC | S11-63           | 15675   | 1    | 0    | 1    |
| 4559_AD | S11-63           | 15675   | 1    | 0    | 1    |
| 4559_AE | S11-9            | 27180   | 0    | 1    | 0    |
| 4559_AH | S15-7            | 22634   | 0    | 0    | 0    |
| 4559_AI | S15-7            | 22634   | 0    | 0    | 0    |
| 4559_AJ | S15-7            | 22634   | 0    | 0    | 0    |
| 4559_AK | S15-T2-15-41     | 2876_X  | 0    | 1    | 0    |
| 4559_AL | S15-T2-15-41     | 2876_X  | 0    | 1    | 0    |
| 4559_AM | S15-T2-15-41     | 2876_X  | 0    | 1    | 0    |
| 4559_AN | S16-T1-15-47     | 2876_J  | 1    | 0    | 1    |
| 4559_AO | S16-T1-15-47     | 2876_J  | 1    | 0    | 1    |
| 4559_AP | S16-T1-15-47     | 2876_J  | 1    | 0    | 1    |
| 4559_AQ | S17-1            | 2876_B  | 0    | 0    | 1    |
| 4559_AR | S17-1            | 2876_B  | 0    | 0    | 1    |
| 4559_AS | S17-1            | 2876_B  | 0    | 0    | 1    |
| 4559_AT | S18-2            | 20683   | 0    | 0    | 0    |
| 4559_AU | S18-2            | 20683   | 0    | 0    | 0    |
| 4559_AV | S18-2            | 20683   | 0    | 0    | 0    |
| 4559_AW | S3-12            | 12912   | 0    | 0    | 1    |
| 4559_AX | S3-12            | 12912   | 0    | 0    | 1    |
| 4559_AY | S3-12            | 12912   | 0    | 0    | 1    |
| 4559_AZ | S3-4             | 13173   | 1    | 0    | 1    |
| 4559_BA | S3-4             | 13173   | 1    | 0    | 1    |
| 4559_BB | S3-4             | 13173   | 1    | 0    | 1    |
| 4559_BC | S4-B2-9          | 13581   | 0    | 1    | 0    |
| 4559_BD | S4-B2-9          | 13581   | 0    | 1    | 0    |
| 4559_BE | S4-B2-9          | 13581   | 0    | 1    | 0    |
| 4559_BF | S5-100           | 22624   | 0    | 0    | 1    |
| 4559_BG | S5-100           | 22624   | 0    | 0    | 1    |
| 4559_BH | S5-100           | 22624   | 0    | 0    | 1    |
| 4559_BI | S7-B2            | 35519   | 0    | 1    | 0    |
| 4559_BJ | S7-B2            | 35519   | 0    | 1    | 0    |
| 4559_BK | S7-B2            | 35519   | 0    | 1    | 0    |
| 4559_BL | S7-B20           | 27172   | 0    | 1    | 0    |
| 4559_BM | S7-B20           | 27172   | 0    | 1    | 0    |
| 4559_BN | S7-B20           | 27172   | 0    | 1    | 0    |
| 4559_BO | S7-B5            | 13578   | 0    | 0    | 0    |
| 4559_BP | S7-B5            | 13578   | 0    | 0    | 0    |
| 4559_BQ | S7-B5            | 13578   | 0    | 0    | 0    |
| 4559_BR | S7-T1-15-2       | 2876_AD | 0    | 1    | 0    |
| 4559_BS | S7-T1-15-2       | 2876_AD | 0    | 1    | 0    |
| 4559_BT | S7-T1-15-2       | 2876_AD | 0    | 1    | 0    |
| 4559_BV | S7-T1-15-89      | 2876_V  | 0    | 0    | 0    |
| 4559_C  | Col-0            | 6909    | 0    | 0    | 0    |
| 4559_D  | Cvi-0            | 4073_M  | 1    | 0    | 1    |
| 4559_E  | Cvi-0            | 4073_M  | 1    | 0    | 1    |
| 4559_F  | Cvi-0            | 4073_M  | 1    | 0    | 1    |
| 4559_J  | S10-16           | 15673   | 0    | 0    | 0    |
| 4559_K  | S10-16           | 15673   | 0    | 0    | 0    |
| 4559_L  | S10-16           | 15673   | 0    | 0    | 0    |
| 4559_M  | S10-29           | 15671   | 0    | 0    | 1    |
| 4559_N  | S10-29           | 15671   | 0    | 0    | 1    |
| 4559_O  | S10-29           | 15671   | 0    | 0    | 1    |
| 4559_P  | S11-100          | 2876_AN | 0    | 0    | 1    |
| 4559_S  | S11-20           | 16293   | 0    | 0    | 1    |
| 4559_T  | S11-20           | 16293   | 0    | 0    | 1    |
| 4559_U  | S11-20           | 16293   | 0    | 0    | 1    |
| 4559_V  | S11-35           | 27174   | 1    | 1    | 1    |
| 4559_Y  | S11-45           | 27175   | 0    | 1    | 0    |
| 4559_Z  | S11-45           | 27175   | 0    | 1    | 0    |
| 4568_A  | S10-102          | 22637   | 1    | 1    | 1    |
| 4568_B  | S10-12           | 27158   | 0    | 1    | 1    |
| 4568_C  | S1-100           | 22615   | 0    | 0    | 0    |
| 4568_D  | S11-101          | 22620   | 1    | 1    | 0    |
| 4568_E  | S11-48           | 27170   | 1    | 0    | 0    |
| 4568_F  | S11-54           | 27160   | 0    | 1    | 1    |
| 4568_G  | S11-61           | 27161   | 1    | 0    | 0    |
| 4568_H  | S15-1            | 22631   | 1    | 0    | 0    |
| 4568_I  | S15-3            | 20682   | 1    | 0    | 0    |
| 4568_J  | S15-6            | 22622   | 0    | 1    | 1    |
| 4568_K  | S15-T1-15-11     | 2876_C  | 1    | 0    | 0    |
| 4568_L  | S15-T1-15-4      | 2876_M  | 1    | 0    | 0    |
| 4568_M  | S15-T2-15-1      | 2876_R  | 1    | 1    | 0    |
| 4568_N  | S15-T2-15-21     | 2876_F  | 1    | 1    | 0    |
| 4568_O  | S16-2            | 2876_AR | 1    | 0    | 1    |
| 4568_P  | S18-3            | 22630   | 0    | 1    | 0    |
| 4568_Q  | S19-1            | 22633   | 1    | 0    | 1    |
| 4568_R  | S3-2             | 13179   | 1    | 0    | 1    |
| 4568_S  | S3-5             | 13183   | 1    | 0    | 1    |
| 4568_T  | S7-B15           | 16150   | 0    | 0    | 0    |
| 4568_U  | S8-B100          | 22626   | 0    | 0    | 0    |
| 4623_A  | S10_101          | 2876_AM | 0    | 1    | 1    |
| 4623_AB | S15_T3_15_2      | 2876_S  | 0    | 1    | 0    |
| 4623_AC | S15_T3_15_27     | 2876_G  | 1    | 0    | 1    |
| 4623_AD | S16_3            | 2876_AS | 1    | 0    | 1    |
| 4623_AE | S16_5            | 20686   | 1    | 0    | 1    |
| 4623_AF | S16_8            | 20685   | 1    | 0    | 1    |
| 4623_AG | S16_L_15_4       | 2876_K  | 1    | 0    | 1    |
| 4623_AH | S16_T1_15_11     | 2876_Q  | 1    | 0    | 1    |
| 4623_AI | S16_T1_15_37     | 2876_L  | 1    | 0    | 1    |
| 4623_AJ | S16_T2_15_1      | 2876_P  | 1    | 0    | 1    |
| 4623_AK | S18_4            | 22643   | 0    | 1    | 0    |
| 4623_AL | S18_5            | 27163   | 0    | 1    | 1    |
| 4623_AM | S19_T2_15_13     | 2876_AA | 1    | 0    | 1    |
| 4623_AN | S3_1             | 13175   | 1    | 0    | 1    |
| 4623_AO | S3_100           | 2876_AT | 1    | 0    | 1    |
| 4623_AP | S3_3             | 13172   | 1    | 0    | 1    |
| 4623_AQ | S4_B2_2          | 2876_AK | 0    | 0    | 1    |
| 4623_AR | S4_B3_14         | 27177   | 1    | 0    | 1    |
| 4623_AS | S5_10            | 2876_AU | 0    | 0    | 1    |
| 4623_AT | S5_101           | 22632   | 1    | 1    | 0    |
| 4623_AU | S5_102           | 22618   | 0    | 0    | 1    |
| 4623_AW | S5_8             | 13177   | 0    | 0    | 1    |
| 4623_AX | S7_B100          | 2876_AV | 0    | 1    | 0    |
| 4623_AY | S7_B11           | 27165   | 0    | 1    | 0    |
| 4623_AZ | S7_T1            | 15669   | 0    | 1    | 0    |
| 4623_B  | S10_105          | 22619   | 0    | 1    | 1    |
| 4623_BA | S7_T100          | 22617   | 0    | 1    | 0    |
| 4623_BB | S7_T1_15_28      | 2876_Z  | 0    | 1    | 0    |
| 4623_BC | S7_T2            | 27179   | 0    | 1    | 0    |
| 4623_BD | S7_T3            | 2876_AW | 0    | 1    | 0    |
| 4623_BE | S8_B9            | 16292   | 0    | 0    | 0    |
| 4623_BF | S4_B3_14         | 27177   | 1    | 0    | 1    |
| 4623_C  | S10_5            | 15672   | 0    | 0    | 0    |
| 4623_D  | S11_102          | 22642   | 0    | 1    | 0    |
| 4623_E  | S11_103          | 22623   | 0    | 1    | 1    |
| 4623_F  | S11_105          | 2876_AO | 0    | 1    | 0    |
| 4623_G  | S11_14           | 15674   | 0    | 1    | 0    |
| 4623_H  | S11_19           | 35517   | 0    | 0    | 1    |
| 4623_I  | S11_28           | 2876_AP | 0    | 0    | 0    |
| 4623_J  | S11_33           | 27169   | 0    | 0    | 0    |
| 4623_K  | S11_36           | 27181   | 1    | 0    | 1    |
| 4623_L  | S11_38           | 16151   | 1    | 0    | 1    |
| 4623_N  | S11_41           | 27182   | 0    | 1    | 0    |
| 4623_P  | S11_60           | 2876_D  | 1    | 0    | 0    |
| 4623_Q  | S11_62           | 27162   | 1    | 0    | 0    |
| 4623_R  | S11_R2_T2_15_233 | 2876_W  | 0    | 0    | 1    |
| 4623_S  | S15_13           | 22616   | 0    | 1    | 0    |
| 4623_T  | S15_14           | 22641   | 0    | 1    | 0    |
| 4623_U  | S15_2            | 20681   | 1    | 0    | 0    |
| 4623_V  | S15_5            | 22013   | 1    | 0    | 1    |
| 4623_W  | S15_8            | 22636   | 0    | 0    | 0    |
| 4623_X  | S15_T1_15_25     | 2876_O  | 1    | 0    | 0    |
| 4623_Y  | S15_T1_15_31     | 2876_N  | 1    | 0    | 0    |
| 4623_Z  | S15_T2_15_13     | 2876_AB | 1    | 1    | 0    |


## Read trimming

Remove reads smaller than 20 nt and nucleotides at 5' and 3' ends with with quality below 35.

```{bash, eval=FALSE}
for i in *.fastq.gz; do
    name=$(basename $i | cut -d. -f1 -)
    if [ ! -e trimmed_reads/${name}.fastq* ]; then
		  zcat $i | cutadapt -m 20 -q 35 -o trimmed_reads/${name}.fastq -
	  fi
done
```

## Mapping

### Get reference genome

```{bash, eval=FALSE}

# Download fasta file
wget https://www.arabidopsis.org/download_files/Genes/TAIR10_genome_release/TAIR10_chromosome_files/TAIR10_chr_all.fas -O TAIR10.fa

# Replace chromosome names to add prefix Chr
sed -i 's/^>\([1-5]\)/>Chr\1/g' TAIR10.fa

```

### Get gene annotation Araport11

Download from https://www.arabidopsis.org/download/index-auto.jsp?dir=%2Fdownload_files%2FGenes%2FAraport11_genome_release the file Araport11_GFF3_genes_transposons.201606.gff.gz

Convert it in gtf with gffread (argument  `-T main output will be GTF instead of GFF3`) (version 0.11.4)

```{bash}
# Uncompress
gunzip Araport11_GFF3_genes_transposons.201606.gff.gz

# Convert with gffread 
gffread Araport11_GFF3_genes_transposons.201606.gff -T -o Araport11_GFF3_genes_transposons.201606_gffread.gtf

# Change the names of mitochondria and chloroplast to match the fasta reference

cut -f1 Araport11_GFF3_genes_transposons.201606_gffread.gtf | sort - | uniq
Chr1
Chr2
Chr3
Chr4
Chr5
ChrC
ChrM

sed -i 's/ChrC/chloroplast/g' Araport11_GFF3_genes_transposons.201606_gffread.gtf
sed -i 's/ChrM/mitochondria/g' Araport11_GFF3_genes_transposons.201606_gffread.gtf

cut -f1 Araport11_GFF3_genes_transposons.201606_gffread.gtf | sort - | uniq
Chr1
Chr2
Chr3
Chr4
Chr5
chloroplast
mitochondria

```

Note that the protocol https://www.nature.com/articles/nprot.2016.095#Tab1 recommends to create a file for exon and intron before creating the HISAT index.

The two files generated by the python scripts hisat2_extract_exons.py and hisat2_extract_splice_sites.py are bed files of the locations of splicing sites and exons and the corresponding strand orientation.

```{bash}
# Get python script
wget https://raw.githubusercontent.com/DaehwanKimLab/hisat2/master/hisat2_extract_exons.py
wget https://raw.githubusercontent.com/DaehwanKimLab/hisat2/master/hisat2_extract_splice_sites.py


# Extract exon and intron coordinates
python hisat2_extract_exons.py ../Araport11_GFF3_genes_transposons.201606_gffread.gtf > ARAPORT11.exon
python hisat2_extract_splice_sites.py ../Araport11_GFF3_genes_transposons.201606_gffread.gtf > ARAPORT11.ss

# Build the index
hisat2-build --ss ARAPORT11.ss --exon ARAPORT11.exon -f TAIR10.fa TAIR10

```

### Mapping 

```{bash, eval=FALSE}
for i in *.fastq.gz; do
  name=$(basename $i | cut -d. -f1)
	hisat2 -p 8 --rna-strandness R --dta -x /path/to/index/TAIR10 -U $i | \
	samtools view -bS -F 4 - | samtools sort - -o ${name}.bam
done
```


## Read counting

### Install HTseq

```{bash, eval=FALSE}
# Install HTseq (version 0.12.4)
pip install --user numpy --upgrade
pip install htseq --upgrade
```

### Gene annotation for htseq

### Keep only CDS and exons

```{bash}
# Keep only exon and CDS
grep -vw 'transcript' Araport11_GFF3_genes_transposons.201606_gffread.gtf > Araport11_GFF3_genes.gtf
```

### Remove miRNAs genes

htseq-count bugs because the miRNA have no gene_id field (only transcript_id). 

```{bash}
grep -v "ath-miR" Araport11_genes.gtf > Araport11_genes_wo_miRNAs.gtf
```

### Counting

```{bash, eval=FALSE}

mkdir read_count_htseq

for i in *bam; do
	name_file=$(basename $i | cut -d. -f1 -)
	if [! -e ./read_count_htseq/${name_file}.count ]; then
	  samtools view $i | \
	  htseq-count -s reverse -t exon -i gene_id - Araport11_genes_wo_miRNAs.gtf > ./read_count_htseq/${name_file}.count
  fi
done
```


### Count merging

Gather the read counts of different samples in one file using the bash script [scripts/merge_counts.sh](merge_counts.sh).

```{bash, eval=FALSE}
cd read_count_htseq

# Create list_file_counts.txt and sample_names.txt file, I would use the library code for sample names
for i in *count; do
  echo $i >> list_file_counts.txt
  echo $i | cut -d. -f1 >> sample_names.txt
done

# Merge
bash merge_counts.sh list_file_counts.txt sample_names.txt > cts.txt

```

The `cts.txt` file contains the raw read count with the samples in columns and the genes in row.


## Analysis in R

### R Libraries

```{r, warning=FALSE, echo=FALSE}
# RNA-seq analysis
library("DESeq2")

# Plotting functions
library("ggplot2")
library("ggpubr")
library(gridExtra)

# Perform Bayesian shrinkage estimators for effect sizes in GLM models
#library("apeglm")

# Subset and organize dataframes
library("dplyr")
library("tidyverse")
library("magrittr")

# Handle DESeResults to Dataframe conversion
library("tibble")

# Test for significant overlaps
library(GeneOverlap)

# Make Venn diagram
library(RVenn)

# Heat map
library("pheatmap")

# Function
give.n <- function(x){
  return(c(y = mean(x), label = length(x)))
}

```


### Load cts and coldata


```{r}
# Load coldata with sample description and variables
coldata <- read.table("data/coldata.txt", header=TRUE, row.names=1, check.names = FALSE)
# Convert the variables into factors
col_names <- names(coldata)
coldata[,col_names] <- lapply(coldata[,col_names] , factor)

# Load cts
# cts <- read.table("data/cts.txt", header=TRUE, row.names=1, check.names = FALSE)

# Turn into a Rds object for smaller size (twice smaller)
# saveRDS(cts,"data/cts.Rds")

# Delete cts.txt file to save space on GitHub
# file.remove("data/cts.txt")

# Load Rds object 
cts <-  readRDS("data/cts.Rds")

### Check that sample names match in both files
all(colnames(cts) == rownames(coldata))

```

### PCA


```{r}
dds <- DESeqDataSetFromMatrix(countData = cts,
                              colData = coldata,
                              design= ~1)

# Keep only genes with at least 10 reads
keep <- rowSums(counts(dds)) >= 10
dds <- dds[keep,]

dds <- DESeq(dds)

# Variance stabilizing transformation
vsd <- vst(dds, blind=FALSE)

# Create PCA
pcaData <- DESeq2::plotPCA(vsd, intgroup=c("sample"), returnData=TRUE)

# Create a population variable by spliting sample
pcaData2 <- pcaData %>% separate(group, c("population","second","third"), "_") %>% select(PC1,PC2,population,sample,name)

# Get percentage variation
percentVar <- round(100 * attr(pcaData, "percentVar"))

p <- ggplot(pcaData2, aes(PC1, PC2, color=population, label = sample)) +  xlab(paste0("PC1: ",percentVar[1],"% variance")) + ylab(paste0("PC2: ",percentVar[2],"% variance")) +  theme_bw()

p + geom_text(size = 4) + ggtitle("PCA RNA-seq (136 samples)") + theme(plot.title = element_text(hjust = 0.5))

```

![](images/PCA_136_samples.png)

We can see that samples cluster partially within populations.

## Replicates analysis

We have in total 19 accessions with 3 replicates and one accession has 2 replicates (S4-B3-14) so 59 samples.

```
Cvi-0
S10-16
S10-29
S11-20
S11-45
S11-63
S15-7
S15-T2-15-41
S16-T1-15-47
S17-1
S18-2
S3-12
S3-4
S4-B2-9
S5-100
S7-B2
S7-B20
S7-B5
S7-T1-15-2
S4-B3-14
```

```{r}
rep_samples <- as.vector(read.table("data/samples_replicates_RNAseq.txt")$V1)

cts_rep <- cts[,rep_samples]

coldata_rep <- coldata[rep_samples,]

# Check if order followed
all(colnames(cts_rep) == rownames(coldata_rep))

```

### PCA analysis

Check distribution of replicates in a PCA

```{r}
dds <- DESeqDataSetFromMatrix(countData = cts_rep,
                              colData = coldata_rep,
                              design= ~1)

# Keep only genes with at least 10 reads
keep <- rowSums(counts(dds)) >= 10
dds <- dds[keep,]

dds <- DESeq(dds)

# Variance stabilizing transformation
vsd <- vst(dds, blind=FALSE)

# Create PCA
pcaData <- DESeq2::plotPCA(vsd, intgroup=c("sample"), returnData=TRUE)

# Get percentage variation
percentVar <- round(100 * attr(pcaData, "percentVar"))

p <- ggplot(pcaData, aes(PC1, PC2, color=sample, label = sample)) +  xlab(paste0("PC1: ",percentVar[1],"% variance")) + ylab(paste0("PC2: ",percentVar[2],"% variance")) +  theme_bw()+  theme(legend.title = element_blank()) + theme(legend.position = "none")

p + geom_text(size = 4) + ggtitle("PCA RNA-seq replicates") + theme(plot.title = element_text(hjust = 0.5))

```

![](images/PCA_replicates.png)

Most biological replicates cluster tightly together, indicating homogenous conditions across the growth chamber (replicates were separated randomly across the trays).


## DEG analysis by VIM2 allele

```{r}
# Remove Col-0
coldata_filtered <- coldata  %>%  filter(sample!="Col_0") %>% droplevels

# I end up with 136 lines

# Filter also cts
cts_filtered <- cts %>% dplyr::select(rownames(coldata_filtered))

# Rename to coldata and cts
coldata <- coldata_filtered
cts <- cts_filtered

rm(coldata_filtered, cts_filtered)

```


```{r}
dds <- DESeqDataSetFromMatrix(countData = cts,
                              colData = coldata,
                              design= ~ VIM2)

keep <- rowSums(counts(dds)) >= 10
dds <- dds[keep,]

## Generate expression model
# Get the read count and perform 3 steps: estimation of size factors, estimation of dispersion
# and negative binomial GLM fitting and Wald Statistics
dds <- DESeq(dds)

resultsNames(dds)

# Create a DESeqResults object
res <- results(dds)

sum(res$padj < 0.05, na.rm=TRUE)


DEG <- as.data.frame(res) %>% rownames_to_column("geneID")

sigDEG <- as.data.frame(res) %>% rownames_to_column("geneID") %>% filter(padj < 0.05)

write.table(sigDEG, "data/significant_679_genes_VIM2_DESeq2.txt", quote=FALSE, row.names=FALSE, sep="\t")


```

679 DEGs


### GO term analysis DEG VIM2


```{r}
# Remove 2 first lines (headers)
sed '1,2d' arabidopsis_araport11.aggregate.gaf | cut -f2 - | \
                cut -d. -f1 - > arabidopsis_araport11.aggregate.gaf.genes



sed '1,2d' arabidopsis_araport11.aggregate.gaf | \
                cut -f5 - > arabidopsis_araport11.aggregate.gaf.go


paste arabidopsis_araport11.aggregate.gaf.go arabidopsis_araport11.aggregate.gaf.genes | \
                sort | uniq > arabidopsis_araport11.aggregate.GO_gene.gaf

```


```{r}
source("S:/git_repositories/GOMAP_maize_B73_NAM5/go_functions.R", chdir = T)

#TERM2GENE <- read.delim("data/arabidopsis_araport11.aggregate.GO_gene.gaf", header=F)
#colnames(TERM2GENE) <- c("GO","gene")

#saveRDS(TERM2GENE, "data/TERM2GENE_araport11.rds")

TERM2GENE <- readRDS("data/TERM2GENE_araport11.rds")

```

```{r}

sigDEG <- read.table("data/significant_679_genes_VIM2_DESeq2.txt", header=T, sep="\t")

# Run the ego_analysis function providing the vector of geneID argument
list_ego_results <- ego_analysis(sigDEG$geneID)

# Check if any of the three analyses yielded GO terms
# with significant p-adjusted value.
lapply(list_ego_results, function(x) sum(x@result$p.adjust < 0.05))

# Turn list of enrichResult objects into one dataframe
df_ego_analysis <- enrichResult2dataframe(list_ego_results)

# Keep only significant hits (here I use alpha risk 5%)
df_ego_analysis_significant <- df_ego_analysis %>% dplyr::filter(p.adjust < 0.05)
```

$ego_BP
[1] 26

$ego_CC
[1] 2

$ego_MF
[1] 6

```{r}
library("viridis")

df_ego_analysis_significant %>% arrange(qvalue) %>% filter(ontology=="BP") %>%
  head(26) %>%
  mutate(Description = fct_reorder(Description, FoldEnrich)) %>%
  ggplot(aes(x=FoldEnrich, y=Description, color=-log10(qvalue))) +
  geom_point(aes(size = Count))  + xlab("Fold enrichment") + 
  ylab("GO term") + 
  ggtitle("BP GO enrichment") +
  theme_bw() +
  theme(axis.text.x = element_text(color="black"),
        axis.text.y = element_text(color="black"),
        axis.ticks = element_line(color = "black")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_size_area(max_size = 10) +
  scale_color_viridis()

```


```{r}


df_ego_analysis_significant %>% arrange(qvalue) %>% filter(ontology=="CC") %>%
  head(2) %>%
  mutate(Description = fct_reorder(Description, FoldEnrich)) %>%
  ggplot(aes(x=FoldEnrich, y=Description, color=-log10(qvalue))) +
  geom_point(aes(size = Count))  + xlab("Fold enrichment") + 
  ylab("GO term") + 
  ggtitle("CC GO enrichment") +
  theme_bw() +
  theme(axis.text.x = element_text(color="black"),
        axis.text.y = element_text(color="black"),
        axis.ticks = element_line(color = "black")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_size_area(max_size = 10) +
  scale_color_viridis()

```

```{r}
library("viridis")

df_ego_analysis_significant %>% arrange(qvalue) %>% filter(ontology=="MF") %>%
  head(10) %>%
  mutate(Description = fct_reorder(Description, FoldEnrich)) %>%
  ggplot(aes(x=FoldEnrich, y=Description, color=-log10(qvalue))) +
  geom_point(aes(size = Count))  + xlab("Fold enrichment") + 
  ylab("GO term") + 
  ggtitle("MF GO enrichment") +
  theme_bw() +
  theme(axis.text.x = element_text(color="black"),
        axis.text.y = element_text(color="black"),
        axis.ticks = element_line(color = "black")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_size_area(max_size = 10) +
  scale_color_viridis()

```


## DEG analysis CMT2 allele

```{r}
dds <- DESeqDataSetFromMatrix(countData = cts,
                              colData = coldata,
                              design= ~ CMT2)

keep <- rowSums(counts(dds)) >= 10
dds <- dds[keep,]

## Generate expression model
# Get the read count and perform 3 steps: estimation of size factors, estimation of dispersion
# and negative binomial GLM fitting and Wald Statistics
dds <- DESeq(dds)

resultsNames(dds)

# Create a DESeqResults object
res <- results(dds)

sum(res$padj < 0.05, na.rm=TRUE)


DEG <- as.data.frame(res) %>% rownames_to_column("geneID")

sigDEG <- as.data.frame(res) %>% rownames_to_column("geneID") %>% filter(padj < 0.05)

write.table(sigDEG, "data/significant_881_genes_CMT2_DESeq2.txt", quote=FALSE, row.names=FALSE, sep="\t")

```
881

### GO term analysis DEG CMT2

```{r}
source("S:/git_repositories/GOMAP_maize_B73_NAM5/go_functions.R", chdir = T)

#TERM2GENE <- read.delim("data/arabidopsis_araport11.aggregate.GO_gene.gaf", header=F)
#colnames(TERM2GENE) <- c("GO","gene")

#saveRDS(TERM2GENE, "data/TERM2GENE_araport11.rds")

TERM2GENE <- readRDS("data/TERM2GENE_araport11.rds")

```

```{r}

sigDEG <- read.table("data/significant_881_genes_CMT2_DESeq2.txt", header=T, sep="\t")

# Run the ego_analysis function providing the vector of geneID argument
list_ego_results <- ego_analysis(sigDEG$geneID)

# Check if any of the three analyses yielded GO terms
# with significant p-adjusted value.
lapply(list_ego_results, function(x) sum(x@result$p.adjust < 0.05))

# Turn list of enrichResult objects into one dataframe
df_ego_analysis <- enrichResult2dataframe(list_ego_results)

# Keep only significant hits (here I use alpha risk 5%)
df_ego_analysis_significant <- df_ego_analysis %>% dplyr::filter(p.adjust < 0.05)
```
$ego_BP
[1] 3

$ego_CC
[1] 1

$ego_MF
[1] 3

```{r}
library("viridis")

df_ego_analysis_significant %>% arrange(qvalue) %>% filter(ontology=="BP") %>%
  head(10) %>%
  mutate(Description = fct_reorder(Description, FoldEnrich)) %>%
  ggplot(aes(x=FoldEnrich, y=Description, color=-log10(qvalue))) +
  geom_point(aes(size = Count))  + xlab("Fold enrichment") + 
  ylab("GO term") + 
  ggtitle("BP GO enrichment") +
  theme_bw() +
  theme(axis.text.x = element_text(color="black"),
        axis.text.y = element_text(color="black"),
        axis.ticks = element_line(color = "black")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_size_area(max_size = 10) +
  scale_color_viridis()

```


## DEG analysis FBX5 allele

```{r}
dds <- DESeqDataSetFromMatrix(countData = cts,
                              colData = coldata,
                              design= ~ FBX5)

keep <- rowSums(counts(dds)) >= 10
dds <- dds[keep,]

## Generate expression model
# Get the read count and perform 3 steps: estimation of size factors, estimation of dispersion
# and negative binomial GLM fitting and Wald Statistics
dds <- DESeq(dds)

resultsNames(dds)

# Create a DESeqResults object
res <- results(dds)

sum(res$padj < 0.05, na.rm=TRUE)

DEG <- as.data.frame(res) %>% rownames_to_column("geneID")

sigDEG <- as.data.frame(res) %>% rownames_to_column("geneID") %>% filter(padj < 0.05)

write.table(sigDEG, "data/significant_2259_genes_FBX5_DESeq2.txt", quote=FALSE, row.names=FALSE, sep="\t")

```

2259 DEGs.


### GO term analysis DEG FBX5

```{r}
source("S:/git_repositories/GOMAP_maize_B73_NAM5/go_functions.R", chdir = T)

#TERM2GENE <- read.delim("data/arabidopsis_araport11.aggregate.GO_gene.gaf", header=F)
#colnames(TERM2GENE) <- c("GO","gene")

#saveRDS(TERM2GENE, "data/TERM2GENE_araport11.rds")

TERM2GENE <- readRDS("data/TERM2GENE_araport11.rds")

```

```{r}

sigDEG <- read.table("data/significant_2259_genes_FBX5_DESeq2.txt", header=T, sep="\t")

# Run the ego_analysis function providing the vector of geneID argument
list_ego_results <- ego_analysis(sigDEG$geneID)

# Check if any of the three analyses yielded GO terms
# with significant p-adjusted value.
lapply(list_ego_results, function(x) sum(x@result$p.adjust < 0.05))

# Turn list of enrichResult objects into one dataframe
df_ego_analysis <- enrichResult2dataframe(list_ego_results)

# Keep only significant hits (here I use alpha risk 5%)
df_ego_analysis_significant <- df_ego_analysis %>% dplyr::filter(p.adjust < 0.05)
```
$ego_BP
[1] 105

$ego_CC
[1] 52

$ego_MF
[1] 18

```{r}
library("viridis")

df_ego_analysis_significant %>% arrange(qvalue) %>% filter(ontology=="BP") %>%
  head(10) %>%
  mutate(Description = fct_reorder(Description, FoldEnrich)) %>%
  ggplot(aes(x=FoldEnrich, y=Description, color=-log10(qvalue))) +
  geom_point(aes(size = Count))  + xlab("Fold enrichment") + 
  ylab("GO term") + 
  ggtitle("BP GO enrichment") +
  theme_bw() +
  theme(axis.text.x = element_text(color="black"),
        axis.text.y = element_text(color="black"),
        axis.ticks = element_line(color = "black")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_size_area(max_size = 10) +
  scale_color_viridis()

```
```{r}
df_ego_analysis_significant %>% arrange(qvalue) %>% filter(ontology=="CC") %>%
  head(10) %>%
  mutate(Description = fct_reorder(Description, FoldEnrich)) %>%
  ggplot(aes(x=FoldEnrich, y=Description, color=-log10(qvalue))) +
  geom_point(aes(size = Count))  + xlab("Fold enrichment") + 
  ylab("GO term") + 
  ggtitle("CC GO enrichment") +
  theme_bw() +
  theme(axis.text.x = element_text(color="black"),
        axis.text.y = element_text(color="black"),
        axis.ticks = element_line(color = "black")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_size_area(max_size = 10) +
  scale_color_viridis()
```
```{r}
df_ego_analysis_significant %>% arrange(qvalue) %>% filter(ontology=="MF") %>%
  head(10) %>%
  mutate(Description = fct_reorder(Description, FoldEnrich)) %>%
  ggplot(aes(x=FoldEnrich, y=Description, color=-log10(qvalue))) +
  geom_point(aes(size = Count))  + xlab("Fold enrichment") + 
  ylab("GO term") + 
  ggtitle("MF GO enrichment") +
  theme_bw() +
  theme(axis.text.x = element_text(color="black"),
        axis.text.y = element_text(color="black"),
        axis.ticks = element_line(color = "black")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_size_area(max_size = 10) +
  scale_color_viridis()
```

## Overlap DEGs

```{r}

require(RVenn)

sigDEG_VIM2 <- read.table("data/significant_679_genes_VIM2_DESeq2.txt", header=T, sep="\t")
sigDEG_CMT2 <- read.table("data/significant_881_genes_CMT2_DESeq2.txt", header=T, sep="\t")
sigDEG_FBX5 <- read.table("data/significant_2259_genes_FBX5_DESeq2.txt", header=T, sep="\t")

set_genes <- list(sigDEG_VIM2$geneID, sigDEG_CMT2$geneID, sigDEG_FBX5$geneID)
set_genes <- Venn(set_genes)
names(set_genes@sets) <- c("VIM2","CMT2","FBX5")

ggvenn(set_genes)

```

```{r}
# Run the ego_analysis function providing the vector of geneID argument
list_ego_results <- ego_analysis(overlap(set_genes))

# Check if any of the three analyses yielded GO terms
# with significant p-adjusted value.
lapply(list_ego_results, function(x) sum(x@result$p.adjust < 0.05))

# Turn list of enrichResult objects into one dataframe
df_ego_analysis <- enrichResult2dataframe(list_ego_results)

# Keep only significant hits (here I use alpha risk 5%)
df_ego_analysis_significant <- df_ego_analysis %>% dplyr::filter(p.adjust < 0.05)

df_ego_analysis_significant %>% arrange(qvalue) %>%
  head(10) %>%
  mutate(Description = fct_reorder(Description, FoldEnrich)) %>%
  ggplot(aes(x=FoldEnrich, y=Description, color=-log10(qvalue))) +
  geom_point(aes(size = Count))  + xlab("Fold enrichment") + 
  ylab("GO term") + 
  ggtitle("MF GO enrichment") +
  theme_bw() +
  theme(axis.text.x = element_text(color="black"),
        axis.text.y = element_text(color="black"),
        axis.ticks = element_line(color = "black")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_size_area(max_size = 10) +
  scale_color_viridis()

```


## DEG permutation

Check how many DEGs we get if we permutate VIM2 alleles across the 136 samples.

```{r}
permutate_deseq2 <- function(vector_allele){
  
  coldata$RAND <- gtools::permute(vector_allele)


  dds <- DESeqDataSetFromMatrix(countData = cts,
                              colData = coldata,
                              design= ~ RAND)

  keep <- rowSums(counts(dds)) >= 10
  dds <- dds[keep,]

  dds <- DESeq(dds, quiet = TRUE)
  
  # Create a DESeqResults object
  res <- results(dds)
  
  nb_DEGs <- sum(res$padj < 0.05, na.rm=TRUE)
  
  return(nb_DEGs)
  
}
```


```{r}

value_sig_VIM2 <- vector("integer", 100L)
for(i in 1:100){value_sig_VIM2[i] <- permutate_deseq2(coldata$VIM2)}
saveRDS(value_sig_VIM2, "data/value_sig_DEG_VIM2_DEG_permutation.Rds")

value_sig_CMT2 <- vector("integer", 100L)
for(i in 1:100){value_sig_CMT2[i] <- permutate_deseq2(coldata$CMT2)}
saveRDS(value_sig_CMT2, "data/value_sig_DEG_CMT2_permutation.Rds")

value_sig_FBX5 <- vector("integer", 100L)
for(i in 1:100){value_sig_FBX5[i] <- permutate_deseq2(coldata$FBX5)}
saveRDS(value_sig_FBX5, "data/value_sig_DEG_FBX5_permutation.Rds")


```


```{r}

plot_permutation <- function(vector_permutation, observed_value){

observed_value <- as.integer(observed_value)
vector_permutation <- as.vector(vector_permutation)

df <- as.data.frame(matrix(nrow=(length(vector_permutation)+1), ncol=1))

names(df) <- "value"

df$value <- as.integer(c(observed_value, vector_permutation))

ggplot(df, aes(x="",y=value)) + 
  geom_boxplot(outlier.shape = NA) + 
  geom_point(position=position_jitter()) + 
  theme_bw() + 
  ylab("Number of significant DEGs") + 
  xlab("") + 
  geom_hline(yintercept=observed_value) + 
  theme(axis.text.x = element_text(color="black"), 
        axis.text.y = element_text(color="black"),
        axis.ticks = element_line(color = "black"))
}

```

```{r}
value_sig_VIM2 <- readRDS("data/value_sig_DEG_VIM2_DEG_permutation.Rds")

p1 <- plot_permutation(value_sig_VIM2, 679) + ggtitle("Permutation VIM2") +  theme(plot.title = element_text(hjust = 0.5))

p2 <- plot_permutation(value_sig_CMT2, 881) + ggtitle("Permutation CMT2") +  theme(plot.title = element_text(hjust = 0.5))

p3 <- plot_permutation(value_sig_FBX5, 2259) + ggtitle("Permutation FBX5") +  theme(plot.title = element_text(hjust = 0.5))

grid.arrange(p1, p2, p3, nrow = 1)

```


## DEG analysis by VIM2 allele

Remove Col-0 4559_C and keep first replicate for each accessions with replicates.

```{r}

coldata_filtered <- coldata  %>% distinct(sample, .keep_all = TRUE) %>% filter(sample!="Col_0")

# I end up with 97 lines

# Filter also cts
cts_filtered <- cts %>% dplyr::select(rownames(coldata_filtered))
  

# Rename to coldata and cts
coldata <- coldata_filtered
cts <- cts_filtered

rm(coldata_filtered, cts_filtered)

```


```{r}
dds <- DESeqDataSetFromMatrix(countData = cts,
                              colData = coldata,
                              design= ~ VIM2)

keep <- rowSums(counts(dds)) >= 10
dds <- dds[keep,]

## Generate expression model
# Get the read count and perform 3 steps: estimation of size factors, estimation of dispersion
# and negative binomial GLM fitting and Wald Statistics
dds <- DESeq(dds)

resultsNames(dds)

# Create a DESeqResults object
res <- results(dds)

```

## PCA analysis

### Extracting transformed values

```{r}
# Variance stabilizing transformation
vsd <- vst(dds, blind=FALSE)

# Create PCA
pcaData <- plotPCA(vsd, intgroup=c("sample", "VIM2"), returnData=TRUE)

# Get percentage variation
percentVar <- round(100 * attr(pcaData, "percentVar"))

p <- ggplot(pcaData, aes(PC1, PC2, color=VIM2, label = sample)) +  xlab(paste0("PC1: ",percentVar[1],"% variance")) + ylab(paste0("PC2: ",percentVar[2],"% variance")) +  theme_bw()

p + geom_text(size = 3) + ggtitle("PCA RNA-seq 97 samples") + theme(plot.title = element_text(hjust = 0.5))

```

![](images/PCA_97_samples.png)
No clear distinction between accessions with VIM2del vs VIM2ref alleles.

## List DEGs for VIM2 allele

```{r}

sum(res$padj < 0.05, na.rm=TRUE)

DEG <- as.data.frame(res) %>% rownames_to_column("geneID")

write.table(DEG, "data/DEGs_VIM2_DESeq2_97_accessions_TAIR10.txt", quote=FALSE, row.names=FALSE, sep="\t")

# Save as rds object
# saveRDS(DEG, "df_DESeq2_VIM2.rds")

sigDEG <- as.data.frame(res) %>% rownames_to_column("geneID") %>% filter(padj < 0.05)

write.table(sigDEG, "data/significant_94_DEGs_VIM2_DESeq2_97_accessions.txt", quote=FALSE, row.names=FALSE, sep="\t")

```

94 DEGs found. Among them, *VIM2/4* and *VIM3*.


### VIM2/VIM4 and VIM3 expression

Combine read counts for *VIM2* and *VIM4* as they are too similar to be able to differentiate their expression.

```{r}
# Get data

# Get data
vim2 <- plotCounts(dds, gene="AT1G66050", intgroup="VIM2", main = "VIM2", returnData = T)
vim4 <- plotCounts(dds, gene="AT1G66040", intgroup="VIM2", main = "VIM2", returnData = T)
vim3 <- plotCounts(dds, gene="AT5G39550", intgroup="VIM2", main = "VIM2", returnData = T)

vim24 <- cbind(vim2, vim4)

# Create a new variable which summarizes the read count
vim24$VIM24_count <-  vim24[,1] + vim24[,3]

# Remove extra VIM2 column
vim24 <- vim24[,-2]

# Highlight Cvi-0
# Get library names
library_Cvi_0 <- coldata %>% filter(sample=="Cvi_0") %>% rownames()

# Get index corresponding in vim24 that got Col-0 removed
index_cvi <- which(rownames(vim24) %in% library_Cvi_0)


p1 <- ggboxplot(vim24, y="VIM24_count", x="VIM2", add="jitter", title="VIM2/4 (AT1G66050/AT1G66040") + theme(plot.title = element_text(hjust = 0.5)) +  ylab("Normalized read count") + xlab("VIM2 allele") + geom_point(data=vim24[index_cvi,], color="red", pch=18, cex=3)
p2 <- ggboxplot(vim3, y="count", x="VIM2", add="jitter", title="VIM3 (AT5G39550)") + ylab("Normalized read count") + xlab("VIM2 allele") + theme(plot.title = element_text(hjust = 0.5)) + geom_point(data=vim3[index_cvi,], color="red", pch=18, cex=3) 

grid.arrange(p1, p2, nrow = 1)

```

![](images/VIM24_VIM3_expression.png)

### Statistical test expression VIM2/4

```{r}

# Count number of genotype
table(vim24$VIM2)

library(onewaytests)

# Test if variances equals
bartlett.test(VIM24_count~VIM2, data=vim24)

# Variance homogenous

# Do t-test (two-tailed)
with(vim24, t.test(VIM24_count[VIM2=="0"], VIM24_count[VIM2=="1"], var.equal=TRUE))

```

```
	Bartlett test of homogeneity of variances

data:  VIM24_count by VIM2
Bartlett's K-squared = 0.74395, df = 1, p-value = 0.3884


	Two Sample t-test

data:  VIM24_count[VIM2 == "0"] and VIM24_count[VIM2 == "1"]
t = -8.3376, df = 95, p-value = 5.822e-13
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -54.70224 -33.66205
sample estimates:
mean of x mean of y 
 36.18342  80.36557 

```

Highly significant different between the two groups VIM2del and VIM2ref.






### GO analysis on the 94 DEGs

Use GO annotation made with GOMAP on fasta file `Araport11_pep_20220914.fa`

File in `arabidopsis_araport11.aggregate.gaf` is the output file


```{bash, eval=FALSE}
cd /home/zicola/SCRIPTS/analysis_RNA-seq_GC4559_4568_4623/data

# Keep only gene ID and GO terms, Remove isoforms
cut -f2,5 arabidopsis_araport11.aggregate.gaf | sed '1,2d' | sed 's/\.[0-9]\+//g' | sort | uniq > arabidopsis_araport11.aggregate_processed.gaf
```

Process file into R object

```{r}

GO_analysis_data <- read.delim("data/arabidopsis_araport11.aggregate_processed.gaf", header=F)
names(GO_analysis_data) <- c("gene","GO" )

# Keep only GO and gene ID
GO_analysis_data <- GO_analysis_data %>% dplyr::select(GO, gene)

saveRDS(GO_analysis_data, "data/GO_analysis_data.rds")

```

### Prepare TERM map for GO (AnnotationDbi)

Get a summary of all 44,509 GO ID and their terms (http://geneontology.org/docs/GO-term-elements)

> Every term has a human-readable term name — e.g. mitochondrion, glucose transmembrane transport, or amino acid binding — and a GO ID, a unique seven digit identifier prefixed by GO:, e.g. GO:0005739, GO:1904659, or GO:0016597

```{r}
# Put GOTermsAnnDbBimap object into a dataframe
df_GOTERM <- as.data.frame(GOTERM)

# Remove first column (otherwise, two redundant column
df_GOTERM <- df_GOTERM[,2:7]

# Create a list of dataframe with terms classified by ontology types
term2name_all <- df_GOTERM %>% dplyr::select(go_id,Term) %>% unique()
term2name_BP <- df_GOTERM %>% dplyr::filter(Ontology == "BP") %>% dplyr::select(go_id,Term) %>% unique()
term2name_CC <- df_GOTERM %>% dplyr::filter(Ontology == "CC") %>% dplyr::select(go_id,Term) %>% unique()
term2name_MF <- df_GOTERM %>% dplyr::filter(Ontology == "MF") %>% dplyr::select(go_id,Term) %>% unique()

# Create a list of dataframe
term2name <- list(ALL=term2name_all, BP=term2name_BP, CC=term2name_CC, MF=term2name_MF)

# Remove useless dataframes
rm(term2name_all, term2name_BP, term2name_CC, term2name_MF,df_GOTERM)

saveRDS(term2name, "data/term2name.rds")

```

```{r}
# Import data in R
geneinformation <- read.delim("data/arabidopsis_araport11.aggregate_processed.gaf", header=F)
colnames(geneinformation) <- c("GO","gene")

saveRDS(geneinformation, "GO_analysis_data.rds")
```

