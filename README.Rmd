---
title: "High impact mutations drive DNA methylation variation after colonization of a novel habitat"
author: "Johan Zicola"
date: "`r format(Sys.time())`"
output:
  html_notebook:
    toc: true
  html_document:
    toc: true
    df_print: paged
  github_document:
    toc: true
  pdf_document:
    toc: true
documentclass: article
classoption: a4paper
geometry: margin=1in
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = FALSE)
```

# Overview

This documentation explains step by step how was performed the analysis on whole-genome bisulfite sequencing (WGBS) data on African *Arabidopsis thaliana* accessions (Morocco and Cape Verde) and the reanalysis of a subset of the WGBS data from the 1001 Genome Project (1001GP) ([Kawakatsu et al., 2016](http://www.sciencedirect.com/science/article/pii/S0092867416308522)).

# Library preparation

Libraries were prepared as described previously in [Urich et al. 2012](http://www.nature.com/nprot/journal/v10/n3/full/nprot.2014.114.html) with minor modifications.

# Sequencing

Libraries were pooled based on the 24 NEXTFlex Bisulfite-Seq barcodes (BiooScientific) for multiplex sequencing on the HiSeq3000 sequencer (Illumina) in 150 bp single-end mode.  1 Gb (7 M reads) of data were ordered for each library (minimum required by the sequencing facility). Reads were trimmed from adapters by the sequencing facility using Cutadapt ([Martin et al., 2011](http://journal.embnet.org/index.php/embnetjournal/article/view/200)). Visual inspection on graphics produced by [fastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) was used to visually determine the quality of the reads.

# Softwares required

* Bismark (v0.19.0)
* Python3.5
* GEMMA (v0.94)
* vcftools (v0.1.14)
* bcftools (v1.2)
* bwa (v0.7.15)
* R (>3.3.0) with the libraries indicated in the scripts
* [SRA tool kit](https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=toolkit_doc) from NCBI
* FastQC v0.11.9
* multiqc v1.6
* cutadapt v2.9
* methylKit (v1.14.2) R package and dependencies

# Reanalysis of the 1001 GP data


## Get information samples

Working directory: `/srv/netscratch/dep_coupland/grp_hancock/johan/bs-seq_data_1001`

Go to NCBI SRA selector for project PRJNA187927 (SALK La Jolla) and PRJNA236110 (GMI Vienna)
Web: https://www.ncbi.nlm.nih.gov/Traces/study/?go=home enter PRJNA187927, Download the SraRunTable.txt (478 samples)

`mv SraRunTable.txt SraRunTable_SALK.txt`

Web: https://www.ncbi.nlm.nih.gov/Traces/study/?go=home enter PRJNA236110, Download the SraRunTable.txt (2215 samples)

`mv SraRunTable.txt SraRunTable_GMI.txt`

Go to http://1001genomes.org/accessions.html and download the csv file (link at the bottom of the page)

Convert CSV to tab-separated file

```{bash}
sed 's/,/\t/g' query.txt > accessions_1001genome.txt
```

A subset of 526 accessions were selected, discarding accessions from USA and replicates. A dataframe containing details about each accessions was created and put in `accessions_1001GP_figure1.txt`.

## Download data

Select SRR names of each the 526 accessions to download

```{bash}
cut -f2 accessions_1001GP_figure1.txt > to_download.txt
```

The script `download_sra.sh` retrieves fastq file for each SRR number.

```{bash}
i=$1

if [[ ! -e ${i}.sra ]]; then
  first_6_chars=$(echo $i | cut -c1-6)
  accession="${i%.*}"
  
  # Download SRA file
  echo "wget ftp://ftp-trace.ncbi.nih.gov/sra/sra-instant/reads/ByRun/sra/SRR/${first_6_chars}/${accession}/${accession}.sra"
  wget ftp://ftp-trace.ncbi.nih.gov/sra/sra-instant/reads/ByRun/sra/SRR/${first_6_chars}/${accession}/${accession}.sra
  
  # Extract fastq file from SRA
  echo "fastq-dump --split-3 ${i}.sra"
  fastq-dump --split-3 ${i}.sra
  
  # Compress fastq file(s) (1 or 2 files for SE or PE libraries, respectively)
  gzip ${i}*.fastq
  
  # Remove SRA file
  rm ${i}.sra
else
  echo "${i}.sra already exists"
fi

```

Download the data

```{bash}

# Launch script in bsub
while read i; do
  bash download_sra.sh $i
done < to_download.txt

```


## Mapping with Bismark

Reads were mapped on *A. thaliana* TAIR10 reference [fasta file](https://www.arabidopsis.org/download_files/Genes/TAIR10_genome_release/TAIR10_chromosome_files/TAIR10_chr_all.fas). Note that the fasta file contains the 5 chromosomes and the 2 plastids (chloroplast and mitochondria). In order to be processed by the R package methylKit ([Akalin et al., 2011](https://doi.org/10.1186/gb-2012-13-10-r87)), the cytosine report files from Bismark were generated for each chromosome and each methylation context. In order to perform the analysis on many accessions, the bash script [run_bismark.sh](scripts/run_bismark.sh) performs Bismark analysis step-by-step.

Note that absolute paths can be given, the output files will be generated in the specified output directory (argument `-o`) or by default in the directory containing the input fastq file if no -o argument is specified. While running, the script will echo each step performed, which can be redirected to a log file.

The script will take care of:
* Building the bismark reference genome
* Perform the alignment
* Remove duplicate reads from the bam file 
* Extract the methylation status and generate coverage and bedGraph files (visualization in SeqMonk and IGV)
* Generate cytosine reports (used as input file for methylKit R package)
* Calculate conversion efficiency (based on spurious non-converted cytosines from the chloroplast genome) 

To get more information on how run_bismark.sh is working:

```{bash}
bash run_bismark.sh -h
```
The code itself contains comments for each step so have look at it and tweak it to your needs.


### Get reference genome

Download the fasta file for *A. thaliana* TAIR10 reference:

```{bash}
# Download fasta file
wget https://www.arabidopsis.org/download_files/Genes/TAIR10_genome_release/TAIR10_chromosome_files/TAIR10_chr_all.fas

# Rename chromosomes to add prefix "Chr" (easier to retrieve information, e.g. Chr1 rather than 1)
sed -i 's/^>\([1-5]\)/>Chr\1/g' TAIR10_chr_all.fas 

# Move the file in "/path/to/dir_fasta/"
mv TAIR10_chr_all.fas /path/to/dir_fasta/

```



### Mapping single-end data

The data from the 1001 GP have a mix of SE and PE data, put fastq files in separate folders.

```{bash}
# Split SE and PE data in different folders
mkdir PE_data
mkdir SE_data

# Move paired-end data in PE_data
mv *_1.fastq.gz PE_data/
mv *_2.fastq.gz PE_data/

# Move the rest (SE data) into SE_data
mv *fastq.gz SE_data

```

Map the reads with the light mode on (remove unnecessary intermediary files) with the flag `-l`

```{bash}
while read i; do
bash run_all_bismark.sh -l -r </path/to/dir_fasta/> -1 ${i} -o </path/to/output/> 
done < <(ls *fastq.gz)

```

#### Assess mapping efficiency

```{bash}

for i in *bismark_bt2_SE_report.txt; do
  library=$(echo $i | cut -d'_' -f1,2)
  map=$(grep "Mapping efficiency" $i | cut -d':' -f2 -)
  echo -e "${library}\t${map}" >> mapping_efficiency.txt
done
```

Put data in excel and calculate average and SD
average: 64.89%
Stdev: 9.34%

#### Assess conversion efficiency

```{bash}
for i in *_report.conversion_efficiency.txt; do 
  name=$(echo $i | cut -d'_' -f1,2) 
  line=$(tail -n1 $i | cut -f3)
  echo $name $line
done >> conversion_efficiency.txt
```

Put data in excel and calculate average and SD

average: 99.52%
Stdev: 0.38%


### Mapping paired-end data

```{bash}

# Get single name for each pair data
ls *fastq.gz | cut -d'_' -f1,2 | uniq > list_fastq_files.txt

while read i; do
          fastq1=${i}_1.fastq.gz
          fastq2=${i}_2.fastq.gz
	        bash run_all_bismark.sh -l -r </path/to/dir_fasta/> -1 $fastq1 -2 $fastq2 -o </path/to/output/> 
done < list_fastq_files.txt

```

#### Assess mapping efficiency

```{bash}

cd /srv/netscratch/dep_coupland/grp_hancock/johan/bs-seq_data_1001/fastq_files/1001/PE_data

for i in *bismark_bt2_PE_report.txt.gz; do
  library=$(echo $i | cut -d'_' -f1,2)
  map=$(zgrep "Mapping efficiency" $i | cut -d':' -f2 -)
  echo -e "${library}\t${map}" >> mapping_efficiency.txt
done
```

average: 51.82%
Stdev: 8.21%

Interestingly, the SE end data map at higher efficiency than PE data (about 10% more uniquely mapped reads) and I observed the same trend for the data of project GC_4050. This is probably due to the fact that more reads are unlinked in SE mode and therefore reads mapping in repetitive regions in PE mode are 2 times more numerous as they belong to the same DNA fragment.

#### Assess conversion efficiency

```{bash}
for i in *_report.conversion_efficiency.txt; do 
  name=$(echo $i | cut -d'_' -f1,2) 
  line=$(tail -n1 $i | cut -f3)
  echo $name $line
done >> conversion_efficiency.txt
```

# Analysis of the accessions from Cape Verde and Morocco

We generated WGBS data for 83 accessions from Cape Verde - Santo Antao, 20 from Morocco and diverse mutants (ARABIDILLO-1 and CMT2). We also included as control the accessions Col-0, Col-3, Doer-10, and UKID116. The data for the fastq files for these samples can be downloaded in the NCBI depository PRJNA612437.

## Download fastq files

1. Go on website https://www.ncbi.nlm.nih.gov/sra and type PRJNA612437.
2. Click to "SRA Experiments"
3. Click on "Send Results to Run selector"
4. Download the SRR list by clicking 'Accession List' as SRR_Acc_List.txt

*NB: The data are all single-end reads*

In bash, download SRA files and convert them in fastq files:

```{bash}
while read name in list; do
	fastq-dump --split-spot $name
done < SRR_Acc_List.txt
```

## Rename fastq files

Change the SRR name to the name of the library

```{bash}
TODO when the data of CPV paper will be in NCBI
Also group needs to agree on name system for fastq files
```

## Run Bismark

For each fastq file, run the following command:

```{bash}
bash run_bismark.sh -1 <filename.fastq> -r </path/to/dir_fasta/> -o </name/output/directory/>
``` 


# Methylation call and DMR

Once Bismark has been run, cytosine report files for each methylation contexts are imported in methylKit R packages for further analysis.

Typical format of the bismark output file imported in methylKit:

The suffix of the file is `*_bismark_bt2.deduplicated.bismark.cov.gz.CHG_report_only_chr.txt` so it contains all the call for cytosines in CHG context, excluding the calls in organelles (chloroplast and mitochondria).

```
Chr4    1004    +       1       1       CHG     CAG
Chr4    1006    -       2       3       CHG     CTG
Chr4    1009    -       0       5       CHG     CCG
Chr4    1020    +       1       3       CHG     CCG
Chr4    1023    -       4       5       CHG     CCG
Chr4    1052    -       9       3       CHG     CCG
Chr4    1071    +       3       4       CHG     CAG
Chr4    1073    -       6       6       CHG     CTG
Chr4    1090    +       4       5       CHG     CCG
Chr4    1096    +       4       5       CHG     CTG

```

The columns represent chromosome, base position, strand position of the cytosine, number of methylated Cs, number unmethylated Cs, methylation context, and trinucleotide context.

Different functions were created to run the functions of methylKit in batch. These functions can be found in [functions_methylkit.R](functions_methylkit.R).


Here is described the pipeline used to process the methylation data in methylKit.



## Annotation Araport11

We need the last annotation of genes and TEs for Col-0. Use Araport11 annotation

Files downloaded from https://www.arabidopsis.org/download/index-auto.jsp?dir=%2Fdownload_files%2FGenes%2FAraport11_genome_release

```{bash}
# Get genes
grep -P "\tgene\t" Araport11_GFF3_genes_transposons.201606.gff  > Araport11_GFF3_genes_only.gff

# Convert gff to bed format
gff2bed < Araport11_GFF3_genes_only.gff > Araport11_GFF3_genes_only_full.bed

# Keep only first 4 columns
cut -f1,2,3,4 Araport11_GFF3_genes_only_full.bed > Araport11_GFF3_genes_only.bed

# For TEs
grep "transposable_element" Araport11_GFF3_genes_transposons.201606.gff | wc -l
35090

# In comparison, there were 35082 transposable_element feature in TAIR10 annotation

grep "transposable_element" Araport11_GFF3_genes_transposons.201606.gff  > Araport11_GFF3_transposons.gff

# Convert gff to bed format
gff2bed < Araport11_GFF3_transposons.gff > Araport11_GFF3_transposons_full.bed

# Keep only first 4 columns
cut -f1,2,3,4 Araport11_GFF3_transposons_full.bed > Araport11_GFF3_transposons.bed


# Keep TEs bigger than 4 kb
cat Araport11_GFF3_transposons.bed | awk -F'\t' '$3-$2 >= 4000 {print $0}' > Araport11_GFF3_transposons_longer_4kb.bed

# Keep TEs smaller than 500 bp
cat Araport11_GFF3_transposons.bed | awk -F'\t' '$3-$2 < 500 {print $0}' > Araport11_GFF3_transposons_smaller_500bp.bed

```



```{r,  message = FALSE}

####################################
#       Libraries and functions    #
####################################

# Load the R script functions_methylkit.R which contains wrap up functions to run in batch several 
# methylKit functions
source("functions_methylkit.R")

####################################
#      Paths to DB directories     #
####################################

# Paths to database for the output files of methylKit
path_DB_CpG="/path/to/methylDB_CpG"
path_DB_CHG="/path/to/methylDB_CHG"
path_DB_CHH="/path/to/methylDB_CHH"

# Create a list of these 3 paths
list_DB_paths <- list(path_DB_CpG, path_DB_CHG, path_DB_CHH, path_DB_CX)

# Path containing cytosine report and bam files from bismark pipeline
path_bismark_files=paste("/path/to/bismark/output/files/", sep="")

####################################################
################# BED FILES ########################
####################################################

# Path to bed files for region analysis
bed_genes <- "Araport11_GFF3_genes_only.bed"

# Get coordinates of the genes body methylated and body methylated + intermediate methylated from Takuno et al., 2017 (https://academic.oup.com/mbe/article/34/6/1479/3059954)
# List sent by Takuno on 2019-06-24
bed_genes_BM <- "BM_gene_ID.bed"
bed_genes_BM_IM <- "BM_IM_gene_ID.bed"

# Analysis on cluster 5 and 6
# # Path to bed files for region analysis (see section 'Analysis of cluster 5 and 6' for details of these bed files)
bed_genes_cluster5 <- paste(path_bed, "cluster5_coordinates.bed", sep="")
bed_genes_cluster6 <- paste(path_bed, "cluster6_coordinates.bed", sep="")


#bed_genes_annotate <- paste(workdir, "Arabidopsis_thaliana.TAIR10.39.bed", sep="") # Version that was made from GTF (works with readTranscriptFeatures)


# All TEs
bed_TEs <- paste(path_bed,"Araport11_GFF3_transposons.bed", sep="")

# TEs longer than 4 kb 
bed_TEs_4kb <- paste(path_bed,"Araport11_GFF3_transposons_longer_4kb.bed", sep="")

# TEs shorter than 500 bp
bed_TEs_500bp <- paste(path_bed,"Araport11_GFF3_transposons_smaller_500bp.bed", sep="")



####################################################
################# ACCESSIONS FILES ########################
####################################################

# Path to file with accession information (several were used in the different analyses and they are all available in GitHub)
path_df_accessions <- "df_accessions.txt"

# Get information of the accessions and generate a table
# Order first the file to export so that the elements are ordered as the fastq files (3542_AA, 3542_AB, ...)
df_accessions <- read.table(path_df_accessions, header = TRUE, stringsAsFactors = TRUE)  

# Order the accession as list.files() list the bismark cytosine report files
df_accessions <- order_df_accessions(df_accessions)

# I need to create an hybrid name otherwise the loading of the file won't respect the original order of the input bismark file
df_accessions$sample <- paste(df_accessions$library, df_accessions$name, sep="_")

# Make a list of samples
list_samples <- as.list(as.vector(df_accessions$sample))

# Get list of treatments and reformat so that the first treatment is 0 (control should be 0 optimally)
# Here I put as example CMT2 allele but the variable used as treatment differ in different analysis
list_treatments <- as.vector(df_accessions$cmt2_allele)

# Change char to numeric to avoid bugs when using unite() function
list_treatments <- as.numeric(list_treatments)

# Vector of the 3 contexts analyzed
context <- c("CpG","CHG", "CHH")

```


# Create methylKit objects

Generate data for the 41 libraries available.

## Create methylRawListDB objects

The function `import_bismark_cytosine_report` will retrieve automatically the different cytosine report files generated by Bismark and will create flat database files, allowing to reduce RAM usage. 

```{r}
import_bismark_cytosine_report(path_bismark_files, list_DB_paths, list_samples, list_treatments)

```

## Load methylRawListDB objects

Once created, load methylRawListDB objects. The files won't actually be loaded but accessed in real time when needed.

```{r}
list_methylRawLists <- load_methylRawListDB(list_DB_paths, type="", list_samples, list_treatments)
```

## Filter methylRawList raw

Keep only cytosine positions that have a define minimum coverage. This threshold is usually set at around 5 in most WGBS analyses but since our samples were sequenced at the minimum depth allowed by the sequencing facility, we defined a lower threshold (minimum 2). This approach is valid considering that we look at pattern across large genomic regions. We assumed we would catch any strong signal if any.

```{r}
filter_methylRawList(list_methylRawLists_raw)
```

## Load filtered methylRawListDB objects
```{r,  message = FALSE}
list_methylRawLists <- load_methylRawListDB(list_DB_paths, type="filtered", list_samples, list_treatments)
```



# Subset genomic regions

We want now to analyze methylation patterns is specific genomic regions. For this, we need to subset our data and generate new DB flat files for the different regions.

## Subset data

```{r,  message = FALSE}

# Create subset for methylRawList
subset_methylObject(list_methylRawLists, list_DB_paths, bed_genes, "genes", "methylRaw")

subset_methylObject(list_methylRawLists, list_DB_paths, bed_TEs, "TEs", "methylRaw")

subset_methylObject(list_methylRawLists, list_DB_paths, bed_TEs_4kb, "TEs_4kb", "methylRaw")

subset_methylObject(list_methylRawLists, list_DB_paths, bed_genes_BM, "genes_BM", "methylRaw")

subset_methylObject(list_methylRawLists, list_DB_paths, bed_genes_BM_IM, "genes_BM_IM", "methylRaw")

subset_methylObject(list_methylRawLists, list_DB_paths, bed_TEs_500bp, "TEs_500bp", "methylRaw")

subset_methylObject(list_methylRawLists, list_DB_paths, bed_genes_cluster5, "genes_cluster5", "methylRaw")

subset_methylObject(list_methylRawLists, list_DB_paths, bed_genes_cluster6, "genes_cluster6", "methylRaw")

```

## Load methylRaw subset data
```{r}

# Load subset data

# Load methylRawListDB objects (without filtering)
list_methylRawLists_genes <- load_methylRawListDB(list_DB_paths, type="genes", list_samples, list_treatments)

list_methylRawLists_TEs <- load_methylRawListDB(list_DB_paths, type="TEs", list_samples, list_treatments)

list_methylRawLists_TEs_4kb <- load_methylRawListDB(list_DB_paths, type="TEs_4kb", list_samples, list_treatments)

list_methylRawLists_TEs_500bp <- load_methylRawListDB_wo_CX(list_DB_paths, type="TEs_500bp", list_samples, list_treatments)

list_methylRawLists_genes_BM <- load_methylRawListDB(list_DB_paths, type="genes_BM", list_samples, list_treatments)

list_methylRawLists_genes_BM_IM <- load_methylRawListDB(list_DB_paths, type="genes_BM_IM", list_samples, list_treatments)


```


# Methylation levels

We want first to visualize the methylation levels in different genomic regions. For this, we extract the weighted methylation levels

## Whole genome
```{r, fig.width=14, fig.height=5}

df_name <- "df_mean_filtered"
title <- "Weighted Methylation Level for genes"

get_df_wml(list_methylRawLists, path_DB, df_name)

load_df_wml(path_DB, df_name)

# Plot (use get() to pass the string name of the dataframe as a R object)
ggplot_all(get(df_name), title = title)

```


## Genes

```{r, fig.width=14, fig.height=5}

df_name <- "df_mean_genes"
title <- "Weighted Methylation Level for genes"

get_df_wml(list_methylRawLists_genes, path_DB, df_name)

load_df_wml(path_DB, df_name)

# Plot (use get() to pass the string name of the dataframe as a R object)
ggplot_all(df_mean_genes, title = title)

```

## All TEs

```{r, fig.width=14, fig.height=5}

df_name <- "df_mean_TEs"
title <- "Weighted Methylation Level for long TEs (>4 kb)"

get_df_wml(list_methylRawLists_TEs, path_DB, df_name)

load_df_wml(path_DB, df_name)

```

## Long TEs

```{r, fig.width=14, fig.height=5}
df_name <- "df_mean_TEs_4kb"
title <- "Weighted Methylation Level for long TEs (>4 kb)"

get_df_wml(list_methylRawLists_TEs_4kb, path_DB, df_name)

load_df_wml(path_DB, df_name)

```


# DMR analysis for the 3 genes


